> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [docs.apiyi.com](https://docs.apiyi.com/api-manual)

> API æ˜“ æ¥å£ä½¿ç”¨æ‰‹å†Œå’Œå‚è€ƒæ–‡æ¡£ï¼Œæœ¬æ‰‹å†Œæä¾› API æ˜“ çš„å®Œæ•´æ¥å£æ–‡æ¡£ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿé›†æˆå’Œä½¿ç”¨æˆ‘ä»¬çš„æœåŠ¡ã€‚

å¹³å°ç‰¹è‰²
----

### OpenAI å…¼å®¹æ¨¡å¼

API æ˜“é‡‡ç”¨ **OpenAI å…¼å®¹æ ¼å¼**ï¼Œè®©æ‚¨å¯ä»¥ç”¨ç»Ÿä¸€çš„æ¥å£è°ƒç”¨ 200 + ä¸»æµå¤§æ¨¡å‹ï¼š **æ”¯æŒçš„æ¨¡å‹å‚å•†ï¼š**

*   ğŸ¤– **OpenAI**ï¼šgpt-4oã€gpt-5-chat-latestã€gpt-3.5-turbo ç­‰
*   ğŸ§  **Anthropic**ï¼šclaude-sonnet-4-20250514ã€claude-opus-4-1-20250805 ç­‰
*   ğŸ’ **Google**ï¼šgemini-2.5-proã€gemini-2.5-flash ç­‰
*   ğŸš€ **xAI**ï¼šgrok-4-0709ã€grok-3 ç­‰
*   ğŸ” **DeepSeek**ï¼šdeepSeek-r1ã€deepSeek-v3 ç­‰
*   ğŸŒŸ **é˜¿é‡Œ**ï¼šQwen ç³»åˆ—æ¨¡å‹
*   ğŸ’¬ **Moonshot**ï¼šKimi æ¨¡å‹ç­‰

### åŠŸèƒ½æ”¯æŒèŒƒå›´

**âœ… æ”¯æŒçš„åŠŸèƒ½ï¼š**

*   ğŸ’¬ **å¯¹è¯è¡¥å…¨**ï¼šChat Completions æ¥å£
*   ğŸ–¼ï¸ **å›¾åƒç”Ÿæˆ**ï¼šgpt-image-1ã€flux-kontext-proã€flux-kontext-max ç­‰
*   ğŸ”Š **è¯­éŸ³å¤„ç†**ï¼šWhisper è½¬å½•
*   ğŸ“Š **åµŒå…¥å‘é‡**ï¼šæ–‡æœ¬å‘é‡åŒ–
*   âš¡ **å‡½æ•°è°ƒç”¨**ï¼šFunction Calling
*   ğŸ“¡ **æµå¼è¾“å‡º**ï¼šå®æ—¶å“åº”
*   ğŸ”§ **OpenAI å‚æ•°**ï¼štemperatureã€top_pã€max_tokens ç­‰
*   ğŸ†• **Responses ç«¯ç‚¹**ï¼šOpenAI æœ€æ–°åŠŸèƒ½

**âŒ ä¸æ”¯æŒçš„åŠŸèƒ½ï¼š**

*   ğŸ”§ å¾®è°ƒæ¥å£ï¼ˆFine-tuningï¼‰
*   ğŸ“ Files ç®¡ç†æ¥å£
*   ğŸ¢ ç»„ç»‡ç®¡ç†æ¥å£
*   ğŸ’³ è®¡è´¹ç®¡ç†æ¥å£

### ç®€å•åˆ‡æ¢æ¨¡å‹

**æ ¸å¿ƒä¼˜åŠ¿ï¼šä¸€å¥—ä»£ç ï¼Œå¤šç§æ¨¡å‹** ç”¨ OpenAI æ ¼å¼è·‘é€šåï¼Œåªéœ€è¦**æ›´æ¢æ¨¡å‹åç§°**å³å¯åˆ‡æ¢åˆ°å…¶ä»–å¤§æ¨¡å‹ï¼š

```
# ä½¿ç”¨GPT-4o
response = client.chat.completions.create(
    model="gpt-4o",  # OpenAIæ¨¡å‹
    messages=[...]
)

# åˆ‡æ¢åˆ°Claudeï¼Œå…¶ä»–ä»£ç å®Œå…¨ä¸å˜ï¼
response = client.chat.completions.create(
    model="claude-3.5-sonnet",  # åªæ”¹æ¨¡å‹å
    messages=[...]
)

# åˆ‡æ¢åˆ°Gemini
response = client.chat.completions.create(
    model="gemini-1.5-pro",  # åªæ”¹æ¨¡å‹å
    messages=[...]
)


```

å¿«é€Ÿå¼€å§‹
----

### è·å– API Key

1.  è®¿é—® [API æ˜“æ§åˆ¶å°](https://api.apiyi.com/token)
2.  ç™»å½•æ‚¨çš„è´¦æˆ·
3.  åœ¨ä»¤ç‰Œç®¡ç†é¡µé¢ç‚¹å‡»â€ æ–°å¢â€ åˆ›å»º API Key
4.  å¤åˆ¶ç”Ÿæˆçš„ API Key ç”¨äºæ¥å£è°ƒç”¨

### æŸ¥çœ‹è¯·æ±‚ç¤ºä¾‹

åœ¨ä»¤ç‰Œç®¡ç†é¡µé¢ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿè·å–å„ç§ç¼–ç¨‹è¯­è¨€çš„ä»£ç ç¤ºä¾‹ï¼š **æ“ä½œæ­¥éª¤ï¼š**

1.  è¿›å…¥ [ä»¤ç‰Œç®¡ç†é¡µé¢](https://api.apiyi.com/token)
2.  æ‰¾åˆ°æ‚¨è¦ä½¿ç”¨çš„ API Key æ‰€åœ¨çš„è¡Œ
3.  ç‚¹å‡»â€ æ“ä½œâ€ åˆ—ä¸­çš„ğŸ”§**å°æ‰³æ‰‹å›¾æ ‡**ï¼ˆå·¥å…·å›¾æ ‡ï¼‰
4.  åœ¨å¼¹å‡ºèœå•ä¸­é€‰æ‹©â€ **è¯·æ±‚ç¤ºä¾‹**â€
5.  æŸ¥çœ‹åŒ…å«ä»¥ä¸‹è¯­è¨€çš„å®Œæ•´ä»£ç ç¤ºä¾‹ï¼š

![](https://mintcdn.com/apiyillc/OMY6ItCc2mC1yzgA/images/apiyi-token-simple-code.png?fit=max&auto=format&n=OMY6ItCc2mC1yzgA&q=85&s=067d8d551cd1d8aaebb833932e6632a5) **æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€ï¼š**

*   **cURL** - å‘½ä»¤è¡Œæµ‹è¯•
*   **Python (SDK)** - ä½¿ç”¨å®˜æ–¹ OpenAI åº“
*   **Python (requests)** - ä½¿ç”¨ requests åº“
*   **Node.js** - JavaScript/TypeScript
*   **Java** - Java åº”ç”¨å¼€å‘
*   **C#** - .NET åº”ç”¨å¼€å‘
*   **Go** - Go è¯­è¨€å¼€å‘
*   **PHP** - Web å¼€å‘
*   **Ruby** - Ruby åº”ç”¨å¼€å‘
*   ä»¥åŠæ›´å¤šè¯­è¨€â€¦

**ä»£ç ç¤ºä¾‹ç‰¹ç‚¹ï¼š**

*   âœ… **å®Œæ•´å¯è¿è¡Œ**ï¼šå¤åˆ¶ç²˜è´´å³å¯ä½¿ç”¨
*   âœ… **å‚æ•°è¯´æ˜**ï¼šè¯¦ç»†çš„å‚æ•°é…ç½®
*   âœ… **é”™è¯¯å¤„ç†**ï¼šåŒ…å«å¼‚å¸¸å¤„ç†é€»è¾‘
*   âœ… **æœ€ä½³å®è·µ**ï¼šéµå¾ªå„è¯­è¨€å¼€å‘è§„èŒƒ

åŸºç¡€ä¿¡æ¯
----

### API ç«¯ç‚¹

*   **ä¸»è¦ç«¯ç‚¹**ï¼š`https://api.apiyi.com/v1`
*   **å¤‡ç”¨ç«¯ç‚¹**ï¼š`https://vip.apiyi.com/v1`

### è®¤è¯æ–¹å¼

æ‰€æœ‰ API è¯·æ±‚éœ€è¦åœ¨ Header ä¸­åŒ…å«è®¤è¯ä¿¡æ¯ï¼š

```
Authorization: Bearer YOUR_API_KEY


```

### è¯·æ±‚æ ¼å¼

*   **Content-Type**ï¼š`application/json`
*   **ç¼–ç æ ¼å¼**ï¼šUTF-8
*   **è¯·æ±‚æ–¹æ³•**ï¼šPOSTï¼ˆå¤§éƒ¨åˆ†æ¥å£ï¼‰

æ ¸å¿ƒæ¥å£
----

### 1. å¯¹è¯è¡¥å…¨ï¼ˆChat Completionsï¼‰

åˆ›å»ºä¸€ä¸ªå¯¹è¯è¡¥å…¨è¯·æ±‚ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€‚ **è¯·æ±‚ç«¯ç‚¹**

```
POST /v1/chat/completions


```

**è¯·æ±‚å‚æ•°**

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>å¿…å¡«</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>model</td><td>string</td><td>æ˜¯</td><td>æ¨¡å‹åç§°ï¼Œå¦‚ <code>gpt-3.5-turbo</code></td></tr><tr><td>messages</td><td>array</td><td>æ˜¯</td><td>å¯¹è¯æ¶ˆæ¯æ•°ç»„</td></tr><tr><td>temperature</td><td>number</td><td>å¦</td><td>é‡‡æ ·æ¸©åº¦ï¼Œ0-2 ä¹‹é—´ï¼Œé»˜è®¤ 1</td></tr><tr><td>max_tokens</td><td>integer</td><td>å¦</td><td>æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•°</td></tr><tr><td>stream</td><td>boolean</td><td>å¦</td><td>æ˜¯å¦æµå¼è¿”å›ï¼Œé»˜è®¤ false</td></tr><tr><td>top_p</td><td>number</td><td>å¦</td><td>æ ¸é‡‡æ ·å‚æ•°ï¼Œ0-1 ä¹‹é—´</td></tr><tr><td>n</td><td>integer</td><td>å¦</td><td>ç”Ÿæˆæ•°é‡ï¼Œé»˜è®¤ 1</td></tr><tr><td>stop</td><td>string/array</td><td>å¦</td><td>åœæ­¢åºåˆ—</td></tr><tr><td>presence_penalty</td><td>number</td><td>å¦</td><td>å­˜åœ¨æƒ©ç½šï¼Œ-2 åˆ° 2 ä¹‹é—´</td></tr><tr><td>frequency_penalty</td><td>number</td><td>å¦</td><td>é¢‘ç‡æƒ©ç½šï¼Œ-2 åˆ° 2 ä¹‹é—´</td></tr></tbody></table>

**æ¶ˆæ¯æ ¼å¼**

```
{
  "role": "system|user|assistant",
  "content": "æ¶ˆæ¯å†…å®¹"
}


```

**å®Œæ•´ä»£ç ç¤ºä¾‹**

*   cURL
    
*   Python (SDK)
    
*   Python (requests)
    
*   Node.js
    
*   Java
    
*   C#
    
*   Go
    
*   PHP
    
*   Ruby
    

```
curl -X POST "https://api.apiyi.com/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
      {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
  }'


```

```
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.apiyi.com/v1"
)

# å‘é€èŠå¤©è¯·æ±‚
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
    ],
    temperature=0.7,
    max_tokens=1000
)

print(response.choices[0].message.content)


```

```
import requests
import json

url = "https://api.apiyi.com/v1/chat/completions"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

data = {
    "model": "gpt-3.5-turbo",
    "messages": [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
}

response = requests.post(url, headers=headers, json=data)
result = response.json()

if response.status_code == 200:
    print(result["choices"][0]["message"]["content"])
else:
    print(f"é”™è¯¯: {result}")


```

```
const OpenAI = require('openai');

const client = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.apiyi.com/v1'
});

async function chatCompletion() {
  try {
    const response = await client.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
      ],
      temperature: 0.7,
      max_tokens: 1000
    });
    
    console.log(response.choices[0].message.content);
  } catch (error) {
    console.error('APIè°ƒç”¨é”™è¯¯:', error);
  }
}

chatCompletion();


```

```
import okhttp3.*;
import com.google.gson.Gson;
import java.io.IOException;
import java.util.*;

public class APIYiExample {
    private static final String API_KEY = "YOUR_API_KEY";
    private static final String BASE_URL = "https://api.apiyi.com/v1";
    
    public static void main(String[] args) throws IOException {
        OkHttpClient client = new OkHttpClient();
        Gson gson = new Gson();
        
        // æ„å»ºè¯·æ±‚ä½“
        Map<String, Object> requestBody = new HashMap<>();
        requestBody.put("model", "gpt-3.5-turbo");
        requestBody.put("temperature", 0.7);
        requestBody.put("max_tokens", 1000);
        
        List<Map<String, String>> messages = Arrays.asList(
            Map.of("role", "system", "content", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"),
            Map.of("role", "user", "content", "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚")
        );
        requestBody.put("messages", messages);
        
        RequestBody body = RequestBody.create(
            gson.toJson(requestBody),
            MediaType.parse("application/json")
        );
        
        Request request = new Request.Builder()
            .url(BASE_URL + "/chat/completions")
            .addHeader("Authorization", "Bearer " + API_KEY)
            .addHeader("Content-Type", "application/json")
            .post(body)
            .build();
        
        try (Response response = client.newCall(request).execute()) {
            System.out.println(response.body().string());
        }
    }
}


```

```
using System;
using System.Net.Http;
using System.Text;
using System.Threading.Tasks;
using Newtonsoft.Json;

class Program
{
    private static readonly string API_KEY = "YOUR_API_KEY";
    private static readonly string BASE_URL = "https://api.apiyi.com/v1";
    
    static async Task Main(string[] args)
    {
        using var client = new HttpClient();
        client.DefaultRequestHeaders.Add("Authorization", $"Bearer {API_KEY}");
        
        var requestBody = new
        {
            model = "gpt-3.5-turbo",
            messages = new[]
            {
                new { role = "system", content = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚" },
                new { role = "user", content = "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚" }
            },
            temperature = 0.7,
            max_tokens = 1000
        };
        
        var json = JsonConvert.SerializeObject(requestBody);
        var content = new StringContent(json, Encoding.UTF8, "application/json");
        
        try
        {
            var response = await client.PostAsync($"{BASE_URL}/chat/completions", content);
            var result = await response.Content.ReadAsStringAsync();
            Console.WriteLine(result);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"é”™è¯¯: {ex.Message}");
        }
    }
}


```

```
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io/ioutil"
    "net/http"
)

type Message struct {
    Role    string `json:"role"`
    Content string `json:"content"`
}

type ChatRequest struct {
    Model       string    `json:"model"`
    Messages    []Message `json:"messages"`
    Temperature float64   `json:"temperature"`
    MaxTokens   int       `json:"max_tokens"`
}

func main() {
    apiKey := "YOUR_API_KEY"
    baseURL := "https://api.apiyi.com/v1"
    
    reqData := ChatRequest{
        Model: "gpt-3.5-turbo",
        Messages: []Message{
            {Role: "system", Content: "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
            {Role: "user", Content: "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"},
        },
        Temperature: 0.7,
        MaxTokens:   1000,
    }
    
    jsonData, _ := json.Marshal(reqData)
    
    req, _ := http.NewRequest("POST", baseURL+"/chat/completions", bytes.NewBuffer(jsonData))
    req.Header.Set("Authorization", "Bearer "+apiKey)
    req.Header.Set("Content-Type", "application/json")
    
    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        fmt.Printf("è¯·æ±‚é”™è¯¯: %v\n", err)
        return
    }
    defer resp.Body.Close()
    
    body, _ := ioutil.ReadAll(resp.Body)
    fmt.Println(string(body))
}


```

```
<?php
$api_key = 'YOUR_API_KEY';
$base_url = 'https://api.apiyi.com/v1';

$data = array(
    'model' => 'gpt-3.5-turbo',
    'messages' => array(
        array('role' => 'system', 'content' => 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚'),
        array('role' => 'user', 'content' => 'ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚')
    ),
    'temperature' => 0.7,
    'max_tokens' => 1000
);

$ch = curl_init();
curl_setopt($ch, CURLOPT_URL, $base_url . '/chat/completions');
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($ch, CURLOPT_HTTPHEADER, array(
    'Authorization: Bearer ' . $api_key,
    'Content-Type: application/json'
));
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($ch);
$http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);
curl_close($ch);

if ($http_code == 200) {
    $result = json_decode($response, true);
    echo $result['choices'][0]['message']['content'];
} else {
    echo "é”™è¯¯: " . $response;
}
?>


```

```
require 'net/http'
require 'json'

api_key = 'YOUR_API_KEY'
base_url = 'https://api.apiyi.com/v1'

uri = URI("#{base_url}/chat/completions")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri)
request['Authorization'] = "Bearer #{api_key}"
request['Content-Type'] = 'application/json'

request.body = {
  model: 'gpt-3.5-turbo',
  messages: [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚' },
    { role: 'user', content: 'ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚' }
  ],
  temperature: 0.7,
  max_tokens: 1000
}.to_json

response = http.request(request)

if response.code == '200'
  result = JSON.parse(response.body)
  puts result['choices'][0]['message']['content']
else
  puts "é”™è¯¯: #{response.body}"
end


```

**å“åº”ç¤ºä¾‹**

```
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1699000000,
  "model": "gpt-3.5-turbo",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you today?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}


```

### 2. æ–‡æœ¬è¡¥å…¨ï¼ˆCompletionsï¼‰

ä¸ºå…¼å®¹æ—§ç‰ˆæ¥å£ä¿ç•™ï¼Œå»ºè®®ä½¿ç”¨ Chat Completionsã€‚ **è¯·æ±‚ç«¯ç‚¹**

**è¯·æ±‚å‚æ•°**

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>å¿…å¡«</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>model</td><td>string</td><td>æ˜¯</td><td>æ¨¡å‹åç§°</td></tr><tr><td>prompt</td><td>string/array</td><td>æ˜¯</td><td>æç¤ºæ–‡æœ¬</td></tr><tr><td>max_tokens</td><td>integer</td><td>å¦</td><td>æœ€å¤§ç”Ÿæˆé•¿åº¦</td></tr><tr><td>temperature</td><td>number</td><td>å¦</td><td>é‡‡æ ·æ¸©åº¦</td></tr><tr><td>top_p</td><td>number</td><td>å¦</td><td>æ ¸é‡‡æ ·å‚æ•°</td></tr><tr><td>n</td><td>integer</td><td>å¦</td><td>ç”Ÿæˆæ•°é‡</td></tr><tr><td>stream</td><td>boolean</td><td>å¦</td><td>æµå¼è¾“å‡º</td></tr><tr><td>stop</td><td>string/array</td><td>å¦</td><td>åœæ­¢åºåˆ—</td></tr></tbody></table>

### 3. åµŒå…¥å‘é‡ï¼ˆEmbeddingsï¼‰

å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚ **è¯·æ±‚ç«¯ç‚¹**

**è¯·æ±‚å‚æ•°**

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>å¿…å¡«</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>model</td><td>string</td><td>æ˜¯</td><td>æ¨¡å‹åç§°ï¼Œå¦‚ <code>text-embedding-ada-002</code></td></tr><tr><td>input</td><td>string/array</td><td>æ˜¯</td><td>è¾“å…¥æ–‡æœ¬</td></tr><tr><td>encoding_format</td><td>string</td><td>å¦</td><td>ç¼–ç æ ¼å¼ï¼Œ<code>float</code> æˆ– <code>base64</code></td></tr></tbody></table>

**å®Œæ•´ä»£ç ç¤ºä¾‹**

*   cURL
    
*   Python (SDK)
    
*   Python (requests)
    
*   Node.js
    

```
curl -X POST "https://api.apiyi.com/v1/embeddings" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "text-embedding-ada-002",
    "input": "è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
  }'


```

```
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.apiyi.com/v1"
)

response = client.embeddings.create(
    model="text-embedding-ada-002",
    input="è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
)

# è·å–å‘é‡
embedding = response.data[0].embedding
print(f"å‘é‡ç»´åº¦: {len(embedding)}")
print(f"å‰5ä¸ªå€¼: {embedding[:5]}")


```

```
import requests
import json

url = "https://api.apiyi.com/v1/embeddings"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

data = {
    "model": "text-embedding-ada-002",
    "input": "è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
}

response = requests.post(url, headers=headers, json=data)
result = response.json()

if response.status_code == 200:
    embedding = result["data"][0]["embedding"]
    print(f"å‘é‡ç»´åº¦: {len(embedding)}")
    print(f"å‘é‡å€¼: {embedding[:5]}")  # æ˜¾ç¤ºå‰5ä¸ªå€¼
else:
    print(f"é”™è¯¯: {result}")


```

```
const OpenAI = require('openai');

const client = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.apiyi.com/v1'
});

async function getEmbedding() {
  try {
    const response = await client.embeddings.create({
      model: 'text-embedding-ada-002',
      input: 'è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹'
    });
    
    const embedding = response.data[0].embedding;
    console.log(`å‘é‡ç»´åº¦: ${embedding.length}`);
    console.log(`å‰5ä¸ªå€¼: ${embedding.slice(0, 5)}`);
  } catch (error) {
    console.error('APIè°ƒç”¨é”™è¯¯:', error);
  }
}

getEmbedding();


```

### 4. å›¾åƒç”Ÿæˆï¼ˆImagesï¼‰

ç”Ÿæˆã€ç¼–è¾‘æˆ–å˜æ¢å›¾åƒã€‚ **ç”Ÿæˆå›¾åƒ**

```
POST /v1/images/generations


```

**è¯·æ±‚å‚æ•°**

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>å¿…å¡«</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>model</td><td>string</td><td>æ˜¯</td><td>æ¨¡å‹åç§°ï¼Œæ¨è <code>gpt-image-1</code></td></tr><tr><td>prompt</td><td>string</td><td>æ˜¯</td><td>å›¾åƒæè¿°æç¤ºè¯</td></tr><tr><td>n</td><td>integer</td><td>å¦</td><td>ç”Ÿæˆæ•°é‡ï¼Œé»˜è®¤ 1</td></tr><tr><td>size</td><td>string</td><td>å¦</td><td>å›¾åƒå°ºå¯¸ï¼š<code>1024x1024</code>, <code>1792x1024</code>, <code>1024x1792</code></td></tr><tr><td>quality</td><td>string</td><td>å¦</td><td>è´¨é‡ï¼š<code>standard</code> æˆ– <code>hd</code></td></tr><tr><td>style</td><td>string</td><td>å¦</td><td>é£æ ¼ï¼š<code>vivid</code> æˆ– <code>natural</code></td></tr></tbody></table>

**å®Œæ•´ä»£ç ç¤ºä¾‹**

*   cURL
    
*   Python (SDK)
    
*   Node.js
    

```
curl -X POST "https://api.apiyi.com/v1/images/generations" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-image-1",
    "prompt": "ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ",
    "n": 1,
    "size": "1024x1024",
    "quality": "hd"
  }'


```

```
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.apiyi.com/v1"
)

response = client.images.generate(
    model="gpt-image-1",  # æ¨èä½¿ç”¨gpt-image-1
    prompt="ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ",
    n=1,
    size="1024x1024",
    quality="hd"
)

# è·å–å›¾ç‰‡URL
image_url = response.data[0].url
print(f"ç”Ÿæˆçš„å›¾ç‰‡: {image_url}")

# ä¸‹è½½å›¾ç‰‡
import requests
img_response = requests.get(image_url)
with open("generated_image.png", "wb") as f:
    f.write(img_response.content)
print("å›¾ç‰‡å·²ä¿å­˜ä¸º generated_image.png")


```

```
const OpenAI = require('openai');
const fs = require('fs');

const client = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.apiyi.com/v1'
});

async function generateImage() {
  try {
    const response = await client.images.generate({
      model: 'gpt-image-1',  // æ¨èä½¿ç”¨gpt-image-1
      prompt: 'ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ',
      n: 1,
      size: '1024x1024',
      quality: 'hd'
    });
    
    const imageUrl = response.data[0].url;
    console.log('ç”Ÿæˆçš„å›¾ç‰‡:', imageUrl);
    
    // ä¸‹è½½å›¾ç‰‡
    const fetch = require('node-fetch');
    const imgResponse = await fetch(imageUrl);
    const buffer = await imgResponse.buffer();
    fs.writeFileSync('generated_image.png', buffer);
    console.log('å›¾ç‰‡å·²ä¿å­˜');
    
  } catch (error) {
    console.error('ç”Ÿæˆå›¾ç‰‡é”™è¯¯:', error);
  }
}

generateImage();


```

### 5. éŸ³é¢‘è½¬æ–‡å­—ï¼ˆAudioï¼‰

è¯­éŸ³è¯†åˆ«å’Œè½¬å½•ã€‚ **è½¬å½•éŸ³é¢‘**

```
POST /v1/audio/transcriptions


```

**è¯·æ±‚å‚æ•°**ï¼ˆForm-Dataï¼‰

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>å¿…å¡«</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>file</td><td>file</td><td>æ˜¯</td><td>éŸ³é¢‘æ–‡ä»¶</td></tr><tr><td>model</td><td>string</td><td>æ˜¯</td><td>æ¨¡å‹åç§°ï¼Œå¦‚ <code>whisper-1</code></td></tr><tr><td>language</td><td>string</td><td>å¦</td><td>è¯­è¨€ä»£ç </td></tr><tr><td>prompt</td><td>string</td><td>å¦</td><td>æŒ‡å¯¼æç¤º</td></tr><tr><td>response_format</td><td>string</td><td>å¦</td><td>å“åº”æ ¼å¼</td></tr><tr><td>temperature</td><td>number</td><td>å¦</td><td>é‡‡æ ·æ¸©åº¦</td></tr></tbody></table>

### 6. æ¨¡å‹åˆ—è¡¨

è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚ **è¯·æ±‚ç«¯ç‚¹**

**å“åº”ç¤ºä¾‹**

```
{
  "object": "list",
  "data": [
    {
      "id": "gpt-3.5-turbo",
      "object": "model",
      "created": 1677610602,
      "owned_by": "openai"
    },
    {
      "id": "gpt-4o",
      "object": "model",
      "created": 1687882411,
      "owned_by": "openai"
    }
  ]
}


```

æµå¼å“åº”
----

### å¼€å¯æµå¼è¾“å‡º

åœ¨è¯·æ±‚ä¸­è®¾ç½® `stream: true`ï¼š

```
{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "Hello"}],
  "stream": true
}


```

### æµå¼å“åº”æ ¼å¼

å“åº”å°†ä»¥ Server-Sent Events (SSE) æ ¼å¼è¿”å›ï¼š

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1699000000,"model":"gpt-3.5-turbo","choices":[{"delta":{"content":"Hello"},"index":0}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1699000000,"model":"gpt-3.5-turbo","choices":[{"delta":{"content":" there"},"index":0}]}

data: [DONE]


```

### å¤„ç†æµå¼å“åº”

*   Python
    
*   JavaScript
    

```
import requests
import json

response = requests.post(
    'https://api.apiyi.com/v1/chat/completions',
    headers={
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    },
    json={
        'model': 'gpt-3.5-turbo',
        'messages': [{'role': 'user', 'content': 'Hello'}],
        'stream': True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        line = line.decode('utf-8')
        if line.startswith('data: '):
            data = line[6:]
            if data != '[DONE]':
                chunk = json.loads(data)
                content = chunk['choices'][0]['delta'].get('content', '')
                print(content, end='')


```

```
const response = await fetch('https://api.apiyi.com/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${apiKey}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'gpt-3.5-turbo',
    messages: [{role: 'user', content: 'Hello'}],
    stream: true
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  const lines = chunk.split('\n');
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = line.slice(6);
      if (data !== '[DONE]') {
        const json = JSON.parse(data);
        const content = json.choices[0].delta.content || '';
        process.stdout.write(content);
      }
    }
  }
}


```

é”™è¯¯å¤„ç†
----

### é”™è¯¯å“åº”æ ¼å¼

```
{
  "error": {
    "message": "Invalid API key provided",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_api_key"
  }
}


```

### å¸¸è§é”™è¯¯ç 

<table><thead><tr><th>é”™è¯¯ç </th><th>HTTP çŠ¶æ€ç </th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>invalid_api_key</td><td>401</td><td>API å¯†é’¥æ— æ•ˆ</td></tr><tr><td>insufficient_quota</td><td>429</td><td>é¢åº¦ä¸è¶³</td></tr><tr><td>model_not_found</td><td>404</td><td>æ¨¡å‹ä¸å­˜åœ¨</td></tr><tr><td>invalid_request_error</td><td>400</td><td>è¯·æ±‚å‚æ•°é”™è¯¯</td></tr><tr><td>server_error</td><td>500</td><td>æœåŠ¡å™¨å†…éƒ¨é”™è¯¯</td></tr><tr><td>rate_limit_exceeded</td><td>429</td><td>è¯·æ±‚é¢‘ç‡è¿‡é«˜</td></tr></tbody></table>

### é”™è¯¯å¤„ç†ç¤ºä¾‹

```
try:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Hello"}]
    )
except Exception as e:
    if hasattr(e, 'status_code'):
        if e.status_code == 401:
            print("APIå¯†é’¥æ— æ•ˆ")
        elif e.status_code == 429:
            print("è¯·æ±‚è¿‡äºé¢‘ç¹æˆ–é¢åº¦ä¸è¶³")
        elif e.status_code == 500:
            print("æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•")
    else:
        print(f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}")


```

æœ€ä½³å®è·µ
----

### 1. è¯·æ±‚ä¼˜åŒ–

*   **åˆç†è®¾ç½® max_tokens**ï¼šé¿å…ä¸å¿…è¦çš„é•¿è¾“å‡º
*   **ä½¿ç”¨ temperature**ï¼šæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
*   **æ‰¹é‡å¤„ç†**ï¼šåˆå¹¶å¤šä¸ªè¯·æ±‚å‡å°‘è°ƒç”¨æ¬¡æ•°

### 2. é”™è¯¯é‡è¯•

å®ç°æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶ï¼š

```
import time
import random

def retry_with_backoff(func, max_retries=3):
    for i in range(max_retries):
        try:
            return func()
        except Exception as e:
            if i == max_retries - 1:
                raise e
            wait_time = (2 ** i) + random.uniform(0, 1)
            time.sleep(wait_time)


```

### 3. å®‰å…¨å»ºè®®

*   **ä¿æŠ¤ API å¯†é’¥**ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨
*   **é™åˆ¶æƒé™**ï¼šä¸ºä¸åŒåº”ç”¨åˆ›å»ºä¸åŒçš„å¯†é’¥
*   **ç›‘æ§ä½¿ç”¨**ï¼šå®šæœŸæ£€æŸ¥ API ä½¿ç”¨æ—¥å¿—

### 4. æ€§èƒ½ä¼˜åŒ–

*   **ä½¿ç”¨æµå¼è¾“å‡º**ï¼šæå‡ç”¨æˆ·ä½“éªŒ
*   **ç¼“å­˜å“åº”**ï¼šå¯¹ç›¸åŒè¯·æ±‚ç¼“å­˜ç»“æœ
*   **å¹¶å‘æ§åˆ¶**ï¼šåˆç†æ§åˆ¶å¹¶å‘è¯·æ±‚æ•°

é€Ÿç‡é™åˆ¶
----

API æ˜“ å®æ–½ä»¥ä¸‹é€Ÿç‡é™åˆ¶ï¼š

<table><thead><tr><th>é™åˆ¶ç±»å‹</th><th>é™åˆ¶å€¼</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>RPM (æ¯åˆ†é’Ÿè¯·æ±‚æ•°)</td><td>3000</td><td>æ¯ä¸ª API å¯†é’¥</td></tr><tr><td>TPM (æ¯åˆ†é’Ÿä»¤ç‰Œæ•°)</td><td>1000000</td><td>æ¯ä¸ª API å¯†é’¥</td></tr><tr><td>å¹¶å‘è¯·æ±‚æ•°</td><td>100</td><td>åŒæ—¶å¤„ç†çš„è¯·æ±‚</td></tr></tbody></table>

è¶…å‡ºé™åˆ¶æ—¶ä¼šè¿”å› 429 é”™è¯¯ï¼Œè¯·åˆç†æ§åˆ¶è¯·æ±‚é¢‘ç‡ã€‚

éœ€è¦å¸®åŠ©ï¼Ÿ
-----

*   æŸ¥çœ‹ [å®Œæ•´ API æ–‡æ¡£](https://docs.apiyi.com/api-reference/introduction)
*   è®¿é—® [API æ˜“å®˜ç½‘](https://api.apiyi.com/)
*   è”ç³»æŠ€æœ¯æ”¯æŒï¼š[support@apiyi.com](mailto:support@apiyi.com)