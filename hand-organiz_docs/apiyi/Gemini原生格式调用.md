> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [docs.apiyi.com](https://docs.apiyi.com/api-capabilities/gemini-native-format)

> é€šè¿‡ API æ˜“ ç›´æ¥ä½¿ç”¨ Gemini å®˜æ–¹åŸç”Ÿæ ¼å¼è¿›è¡Œ API è°ƒç”¨ã€‚

API æ˜“ é™¤äº†æ”¯æŒ OpenAI å…¼å®¹æ ¼å¼å¤–ï¼Œä¹Ÿæä¾›äº†ç›´æ¥ä½¿ç”¨ **Gemini å®˜æ–¹åŸç”Ÿæ ¼å¼**è¿›è¡Œ API è°ƒç”¨çš„èƒ½åŠ›ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥æ— ç¼è¿ç§»ç°æœ‰çš„ Gemini ä»£ç ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ Gemini å®˜æ–¹ SDK çš„åŸç”Ÿè¯·æ±‚ä½“ä¸ API æ˜“ äº¤äº’ã€‚

ä¼˜åŠ¿
--

*   **æ— ç¼å…¼å®¹**ï¼šç›´æ¥ä½¿ç”¨ Gemini å®˜æ–¹è¯·æ±‚å’Œå“åº”ç»“æ„ï¼Œæ— éœ€ä»»ä½•è½¬æ¢ã€‚
*   **åŠŸèƒ½å®Œæ•´**ï¼šæ”¯æŒ Gemini çš„æ‰€æœ‰åŸç”Ÿç‰¹æ€§ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€è¾“å…¥ï¼ˆæ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘ï¼‰ã€Function Callingã€ä»£ç æ‰§è¡Œç­‰ã€‚
*   **æ¨ç†èƒ½åŠ›**ï¼šå®Œæ•´æ”¯æŒ Gemini 2.5 ç³»åˆ—çš„æ€ç»´é“¾æ¨ç†åŠŸèƒ½ã€‚
*   **ä¾¿æ·è¿ç§»**ï¼šå¯¹äºå·²æœ‰ Gemini é¡¹ç›®çš„ç”¨æˆ·ï¼Œå¯ä»¥å¿«é€Ÿåˆ‡æ¢åˆ° API æ˜“ï¼Œäº«å—æ›´çµæ´»çš„æœåŠ¡ã€‚

é…ç½®ä¸ä½¿ç”¨
-----

è¦ä½¿ç”¨ Gemini åŸç”Ÿæ ¼å¼ï¼Œæ‚¨éœ€è¦å°† API è¯·æ±‚å‘é€åˆ°ç‰¹å®šçš„ `/v1beta/` ç«¯ç‚¹ã€‚

### ç¯å¢ƒå‡†å¤‡

é¦–å…ˆï¼Œç¡®ä¿æ‚¨å·²å®‰è£… `google-genai` åº“ï¼š

### åŸºç¡€é…ç½®

é…ç½® API æ˜“ æœåŠ¡ç«¯ç‚¹ï¼š

```
from google import genai

{/* é…ç½® APIæ˜“ æœåŠ¡ */}
client = genai.Client(
    api_key="YOUR_API_KEY",  # æ‚¨çš„ APIæ˜“ å¯†é’¥
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* ä½¿ç”¨ Gemini æ¨¡å‹ç”Ÿæˆå†…å®¹ */}
response = client.models.generate_content(
    model='gemini-3-pro-preview',
    contents='æ‚¨çš„æç¤ºè¯'
)
print(response.text)


```

åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
------

### éæµå¼å“åº”

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* å‘é€è¯·æ±‚ */}
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents="è®²ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½çš„ç§‘å¹»æ•…äº‹ã€‚"
)

{/* è¾“å‡ºç»“æœ */}
print(response.text)


```

### æµå¼å“åº”

å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆï¼Œæ¨èä½¿ç”¨æµå¼å“åº”ä»¥è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼š

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* æµå¼ç”Ÿæˆ */}
response = client.models.generate_content_stream(
    model='gemini-2.5-flash',
    contents="è¯·å†™ä¸€ç¯‡å…³äºé‡å­è®¡ç®—çš„è¯¦ç»†æ–‡ç« ã€‚"
)

{/* å®æ—¶è¾“å‡º */}
for chunk in response:
    print(chunk.text, end='', flush=True)


```

Gemini 2.5 ç³»åˆ—æ¨ç†åŠŸèƒ½
-----------------

Gemini 2.5 ç³»åˆ—æ¨¡å‹æ”¯æŒå¼ºå¤§çš„æ€ç»´é“¾æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾ç¤ºæ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ã€‚

### æ¨ç†æ¨¡å‹ç±»å‹

*   **gemini-2.5-flash**ï¼šæ··åˆæ¨ç†å‹ï¼Œå¯é€šè¿‡ `thinking_budget` å‚æ•°è°ƒæ•´æ¨ç†æ·±åº¦ï¼ˆèŒƒå›´ï¼š0-16384 tokensï¼‰
*   **gemini-2.5-pro**ï¼šçº¯æ¨ç†å‹ï¼Œè‡ªåŠ¨å¯ç”¨æ€ç»´é“¾æ¨ç†ï¼Œæ— æ³•å…³é—­

### æ§åˆ¶æ¨ç†é¢„ç®—

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* ä½¿ç”¨æ¨ç†é¢„ç®—é…ç½® */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿï¼Ÿè¯·è¯¦ç»†åˆ†æå„ä¸ªæŠ€æœ¯æ–¹æ¡ˆã€‚",
    config={
        "thinking_budget": 8192,  # æ¨ç†é¢„ç®—ï¼š0-16384
        "temperature": 1.0        # æ¸©åº¦èŒƒå›´ï¼š0-2
    }
)

print(response.text)


```

### æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹

å¦‚æœæ‚¨æƒ³çœ‹åˆ°æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ï¼ˆthinking tokensï¼‰ï¼Œå¯ä»¥è®¾ç½® `include_thoughts=True`ï¼š

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* å¯ç”¨æ€è€ƒè¿‡ç¨‹æ˜¾ç¤º */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="åˆ†æä»¥ä¸‹ä»£ç çš„æ—¶é—´å¤æ‚åº¦ï¼šdef fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)",
    config={
        "thinking_budget": 8192,
        "include_thoughts": True  # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
    }
)

{/* éå†æ‰€æœ‰éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æ€è€ƒè¿‡ç¨‹ */}
for part in response.candidates[0].content.parts:
    if hasattr(part, 'thought') and part.thought:
        print(f"ğŸ’­ æ€è€ƒè¿‡ç¨‹: {part.text}")
    else:
        print(f"ğŸ“ æœ€ç»ˆç­”æ¡ˆ: {part.text}")


```

å¤šæ¨¡æ€å¤„ç†
-----

Gemini æ¨¡å‹æ”¯æŒå¤„ç†å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šç§åª’ä½“ç±»å‹ã€‚

### å›¾ç‰‡å¤„ç†

```
from google import genai
from PIL import Image

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* åŠ è½½æœ¬åœ°å›¾ç‰‡ */}
img = Image.open('path/to/your/image.jpg')

{/* å¤šæ¨¡æ€è¯·æ±‚ */}
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents=[
        "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ ã€é¢œè‰²ã€æ„å›¾ç­‰ã€‚",
        img
    ]
)

print(response.text)


```

### è§†é¢‘å¤„ç†

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* ä¸Šä¼ è§†é¢‘æ–‡ä»¶ */}
video_file = client.files.upload(path='path/to/video.mp4')

{/* åˆ†æè§†é¢‘å†…å®¹ */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents=[
        "è¯·æ€»ç»“è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚",
        video_file
    ]
)

print(response.text)


```

### éŸ³é¢‘å¤„ç†

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ */}
audio_file = client.files.upload(path='path/to/audio.mp3')

{/* è½¬å½•å’Œåˆ†æéŸ³é¢‘ */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents=[
        "è¯·è½¬å½•è¿™æ®µéŸ³é¢‘çš„å†…å®¹ï¼Œå¹¶æ€»ç»“ä¸»è¦è¯é¢˜ã€‚",
        audio_file
    ]
)

print(response.text)


```

### åª’ä½“åˆ†è¾¨ç‡ä¼˜åŒ–

ä¸ºäº†èŠ‚çœ tokens è´¹ç”¨ï¼Œæ‚¨å¯ä»¥è°ƒæ•´åª’ä½“æ–‡ä»¶çš„åˆ†è¾¨ç‡ï¼š

```
from google import genai
from PIL import Image

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* ä½¿ç”¨è¾ƒä½åˆ†è¾¨ç‡å¤„ç†å›¾ç‰‡ï¼ŒèŠ‚çœè´¹ç”¨ */}
img = Image.open('large_image.jpg')

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents=[
        "è¿™å¼ å›¾ç‰‡çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ",
        img
    ],
    config={
        "response_modalities": ["TEXT"],
        "media_resolution": "MEDIA_RESOLUTION_LOW"  # LOW | MEDIUM | HIGH
    }
)

print(response.text)


```

ä»£ç æ‰§è¡ŒåŠŸèƒ½
------

Gemini æ¨¡å‹æ”¯æŒè‡ªåŠ¨æ‰§è¡Œ Python ä»£ç ï¼Œéå¸¸é€‚åˆæ•°æ®åˆ†æåœºæ™¯ã€‚

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* æ•°æ®åˆ†æç¤ºä¾‹ï¼Œå¯ç”¨ä»£ç æ‰§è¡Œå·¥å…· */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="""
å‡è®¾æˆ‘æœ‰ä»¥ä¸‹é”€å”®æ•°æ®ï¼š
- äº§å“Aï¼š100ä»¶ï¼Œå•ä»·50å…ƒ
- äº§å“Bï¼š200ä»¶ï¼Œå•ä»·30å…ƒ
- äº§å“Cï¼š150ä»¶ï¼Œå•ä»·40å…ƒ

è¯·è®¡ç®—ï¼š
1. æ€»é”€å”®é¢
2. å¹³å‡å•ä»·
3. ç»˜åˆ¶é”€å”®é¢åˆ†å¸ƒçš„æŸ±çŠ¶å›¾
""",
    config={'tools': [{'code_execution': {}}]}
)

{/* æŸ¥çœ‹æ‰§è¡Œçš„ä»£ç å’Œç»“æœ */}
for part in response.candidates[0].content.parts:
    if hasattr(part, 'executable_code'):
        print(f"æ‰§è¡Œçš„ä»£ç :\n{part.executable_code.code}")
    if hasattr(part, 'code_execution_result'):
        print(f"æ‰§è¡Œç»“æœ:\n{part.code_execution_result.output}")
    if hasattr(part, 'text'):
        print(f"åˆ†æè¯´æ˜:\n{part.text}")


```

Function Callingï¼ˆå·¥å…·è°ƒç”¨ï¼‰
----------------------

Gemini åŸç”Ÿæ ¼å¼å®Œæ•´æ”¯æŒ Function Callingï¼Œè®©æ¨¡å‹å¯ä»¥è°ƒç”¨å¤–éƒ¨å·¥å…·ã€‚

### å®šä¹‰å·¥å…·

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* å®šä¹‰å¤©æ°”æŸ¥è¯¢å·¥å…· */}
tools = [
    {
        "function_declarations": [
            {
                "name": "get_current_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                        },
                        "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"],
                            "description": "æ¸©åº¦å•ä½"
                        }
                    },
                    "required": ["location"]
                }
            }
        ]
    }
]


```

### è‡ªåŠ¨å·¥å…·è°ƒç”¨

```
from google import genai

{/* è®¾ç½®å·¥å…·è°ƒç”¨æ¨¡å¼ */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="åŒ—äº¬ç°åœ¨çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿæ¸©åº¦æ˜¯å¤šå°‘æ‘„æ°åº¦ï¼Ÿ",
    config={
        'tools': tools,
        'tool_config': {'function_calling_config': {'mode': 'AUTO'}}
    }
)

{/* æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…· */}
function_call = response.candidates[0].content.parts[0].function_call

if function_call:
    print(f"è°ƒç”¨å·¥å…·: {function_call.name}")
    print(f"å‚æ•°: {dict(function_call.args)}")

    {/* å®é™…è°ƒç”¨æ‚¨çš„å¤©æ°” API */}
    def get_current_weather(location, unit="celsius"):
        # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„å¤©æ°” API
        return {
            "location": location,
            "temperature": 22,
            "unit": unit,
            "condition": "æ™´æœ—"
        }

    {/* è·å–å·¥å…·æ‰§è¡Œç»“æœ */}
    weather_data = get_current_weather(**dict(function_call.args))

    {/* å°†ç»“æœè¿”å›ç»™æ¨¡å‹ */}
    from google.genai import types

    response = client.models.generate_content(
        model='gemini-2.5-flash',
        contents=[
            types.Content(
                parts=[
                    types.Part(
                        function_response=types.FunctionResponse(
                            name=function_call.name,
                            response=weather_data
                        )
                    )
                ]
            )
        ]
    )

    print(f"æœ€ç»ˆå›ç­”: {response.text}")


```

ä¸Šä¸‹æ–‡ç¼“å­˜
-----

API æ˜“ è‡ªåŠ¨ä¸º Gemini åŸç”Ÿæ ¼å¼å¯ç”¨éšå¼ä¸Šä¸‹æ–‡ç¼“å­˜ï¼Œå¯ä»¥æ˜¾è‘—é™ä½é‡å¤å¯¹è¯çš„è´¹ç”¨ã€‚

### ç¼“å­˜æœºåˆ¶

*   **è‡ªåŠ¨å¯ç”¨**ï¼šæ— éœ€æ‰‹åŠ¨é…ç½®ï¼Œç³»ç»Ÿè‡ªåŠ¨ç¼“å­˜ä¸Šä¸‹æ–‡
*   **ç¼“å­˜è´¹ç”¨**ï¼šç¼“å­˜çš„ tokens æŒ‰æ­£å¸¸ä»·æ ¼çš„ 25% è®¡è´¹
*   **æœ‰æ•ˆæœŸ**ï¼šç¼“å­˜ä¼šåœ¨ä¸€å®šæ—¶é—´åè‡ªåŠ¨è¿‡æœŸ

### æ£€æµ‹ç¼“å­˜å‘½ä¸­

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* å‘é€è¯·æ±‚ */}
response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹é‡å­è®¡ç®—ã€‚"
)

{/* æ£€æŸ¥ç¼“å­˜å‘½ä¸­ */}
usage = response.usage_metadata
if hasattr(usage, 'cached_content_token_count'):
    print(f"ç¼“å­˜å‘½ä¸­ tokens: {usage.cached_content_token_count}")
    print(f"è¾“å…¥ tokens: {usage.prompt_token_count}")
    print(f"è¾“å‡º tokens: {usage.candidates_token_count}")


```

Tokens ç”¨é‡è¿½è¸ª
-----------

æ¯æ¬¡ API è°ƒç”¨éƒ½ä¼šè¿”å›è¯¦ç»†çš„ tokens ç”¨é‡ä¿¡æ¯ã€‚

### è·å–ç”¨é‡ç»Ÿè®¡

```
from google import genai

client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents="è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†ã€‚"
)

{/* è·å–ç”¨é‡å…ƒæ•°æ® */}
usage = response.usage_metadata

print(f"æç¤ºè¯ tokens: {usage.prompt_token_count}")
print(f"è¾“å‡º tokens: {usage.candidates_token_count}")
print(f"æ€»è®¡ tokens: {usage.total_token_count}")

{/* å¦‚æœæœ‰ç¼“å­˜å‘½ä¸­ */}
if hasattr(usage, 'cached_content_token_count'):
    print(f"ç¼“å­˜ tokens: {usage.cached_content_token_count}")

{/* å¦‚æœæœ‰æ¨ç† tokensï¼ˆGemini 2.5 ç³»åˆ—ï¼‰*/}
if hasattr(usage, 'thoughts_token_count'):
    print(f"æ¨ç† tokens: {usage.thoughts_token_count}")


```

### Tokens å­—æ®µè¯´æ˜

<table><thead><tr><th>å­—æ®µ</th><th>è¯´æ˜</th><th>è®¡è´¹</th></tr></thead><tbody><tr><td><code>prompt_token_count</code></td><td>è¾“å…¥æç¤ºè¯çš„ tokens æ•°é‡</td><td>æŒ‰è¾“å…¥ä»·æ ¼è®¡è´¹</td></tr><tr><td><code>candidates_token_count</code></td><td>è¾“å‡ºå†…å®¹çš„ tokens æ•°é‡</td><td>æŒ‰è¾“å‡ºä»·æ ¼è®¡è´¹</td></tr><tr><td><code>cached_content_token_count</code></td><td>ç¼“å­˜å‘½ä¸­çš„ tokens æ•°é‡</td><td>æŒ‰è¾“å…¥ä»·æ ¼çš„ 25% è®¡è´¹</td></tr><tr><td><code>thoughts_token_count</code></td><td>æ¨ç†è¿‡ç¨‹çš„ tokens æ•°é‡</td><td>æŒ‰è¾“å‡ºä»·æ ¼è®¡è´¹</td></tr><tr><td><code>total_token_count</code></td><td>æ€»è®¡ tokens æ•°é‡</td><td data-numeric="true">-</td></tr></tbody></table>

æ³¨æ„äº‹é¡¹
----

ä¸ OpenAI å…¼å®¹æ ¼å¼çš„å¯¹æ¯”
----------------

<table><thead><tr><th>ç‰¹æ€§</th><th>Gemini åŸç”Ÿæ ¼å¼</th><th>OpenAI å…¼å®¹æ ¼å¼</th></tr></thead><tbody><tr><td><strong>ç«¯ç‚¹</strong></td><td><code>https://api.apiyi.com</code></td><td><code>https://api.apiyi.com/v1/chat/completions</code></td></tr><tr><td><strong>SDK</strong></td><td><code>google-genai</code></td><td><code>openai</code></td></tr><tr><td><strong>æ¨ç†æ§åˆ¶</strong></td><td><code>thinking_budget</code> (0-16384)</td><td><code>reasoning_effort</code> (low/medium/high)</td></tr><tr><td><strong>æ€è€ƒè¿‡ç¨‹</strong></td><td><code>include_thoughts=True</code></td><td>ä¸æ”¯æŒ</td></tr><tr><td><strong>ä»£ç æ‰§è¡Œ</strong></td><td><code>tools=[{'code_execution': {}}]</code></td><td>ä¸æ”¯æŒ</td></tr><tr><td><strong>åª’ä½“ä¸Šä¼ </strong></td><td><code>client.files.upload()</code></td><td>Base64 ç¼–ç </td></tr><tr><td><strong>ç¼“å­˜æ£€æµ‹</strong></td><td><code>cached_content_token_count</code></td><td>æ— è¯¦ç»†å­—æ®µ</td></tr></tbody></table>

å®Œæ•´ç¤ºä¾‹
----

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç»¼åˆç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¤šç§åŠŸèƒ½çš„ç»„åˆä½¿ç”¨ï¼š

```
from google import genai
from PIL import Image

{/* é…ç½® */}
client = genai.Client(
    api_key="YOUR_API_KEY",
    http_options={"base_url": "https://api.apiyi.com"}
)

{/* å®šä¹‰å·¥å…· */}
tools = [{
    "function_declarations": [{
        "name": "search_database",
        "description": "æœç´¢äº§å“æ•°æ®åº“",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
            },
            "required": ["query"]
        }
    }]
}]

{/* å¤šæ¨¡æ€ + å·¥å…·è°ƒç”¨ + æµå¼è¾“å‡º */}
img = Image.open('product.jpg')

response = client.models.generate_content_stream(
    model='gemini-2.5-flash',
    contents=[
        "è¿™å¼ å›¾ç‰‡ä¸­çš„äº§å“æ˜¯ä»€ä¹ˆï¼Ÿè¯·æœç´¢æ•°æ®åº“æŸ¥æ‰¾ç±»ä¼¼äº§å“ï¼Œå¹¶æ¨èç»™æˆ‘ã€‚",
        img
    ],
    config={
        'tools': tools,
        'tool_config': {'function_calling_config': {'mode': 'AUTO'}},
        'thinking_budget': 4096,
        'temperature': 0.7,
        'include_thoughts': False
    }
)

{/* å¤„ç†æµå¼å“åº” */}
for chunk in response:
    if chunk.text:
        print(chunk.text, end='', flush=True)

    {/* æ£€æŸ¥å·¥å…·è°ƒç”¨ */}
    if chunk.candidates and chunk.candidates[0].content.parts:
        for part in chunk.candidates[0].content.parts:
            if hasattr(part, 'function_call'):
                print(f"\n[è°ƒç”¨å·¥å…·: {part.function_call.name}]")

{/* æŸ¥çœ‹æœ€ç»ˆç”¨é‡ï¼ˆéœ€è¦ç­‰å¾…æµå¼å“åº”å®Œå…¨ç»“æŸï¼‰*/}
if hasattr(response, 'usage_metadata'):
    print(f"\n\nTokens ç”¨é‡: {response.usage_metadata.total_token_count}")


```
## æ³¨æ„
VEO ç³»åˆ—æ¨¡å‹ï¼Œç›®å‰è¿˜ä¸æ”¯æŒé€šè¿‡åŸç”ŸSDKè°ƒç”¨ã€‚