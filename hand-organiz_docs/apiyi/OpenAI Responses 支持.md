> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [docs.apiyi.com](https://docs.apiyi.com/api-capabilities/openai-responses)

> æ–°ä¸€ä»£æ™ºèƒ½ä½“ API - ç»“åˆå¯¹è¯è¡¥å…¨çš„ç®€æ´æ€§ä¸å¼ºå¤§çš„å·¥å…·è°ƒç”¨èƒ½åŠ›

API æ˜“ å…¨é¢æ”¯æŒ OpenAI æœ€æ–°çš„ Responses APIï¼Œè¿™æ˜¯ 2025 å¹´ 3 æœˆæ¨å‡ºçš„æ–°ä¸€ä»£æ™ºèƒ½ä½“æ„å»ºæ¥å£ã€‚Responses API ç»“åˆäº† Chat Completions çš„ç®€æ´æ€§ä¸ Assistants API çš„å·¥å…·ä½¿ç”¨å’ŒçŠ¶æ€ç®¡ç†èƒ½åŠ›ï¼Œä¸ºå¼€å‘è€…æä¾›æ›´çµæ´»ã€æ›´å¼ºå¤§çš„ AI åº”ç”¨æ„å»ºä½“éªŒã€‚

ğŸš€ æ ¸å¿ƒç‰¹æ€§
-------

ğŸ“‹ æ”¯æŒçš„æ¨¡å‹
--------

### æ¨ç†æ¨¡å‹ï¼ˆæ¨èï¼‰

*   **O3 ç³»åˆ—**ï¼š`o3`, `o3-pro`, `o4-mini`
*   **ç‰¹è‰²**ï¼šæ¨ç†ä»¤ç‰Œè·¨è¯·æ±‚ä¿æŒï¼Œæä¾›æ›´æ™ºèƒ½çš„ä¸Šä¸‹æ–‡ç†è§£

### å¯¹è¯æ¨¡å‹

*   **GPT-4.1 ç³»åˆ—**ï¼š`gpt-4.1`, `gpt-4.1-mini`
*   **ç‰¹è‰²**ï¼šå¼ºå¤§çš„å·¥å…·è°ƒç”¨å’Œå¤šæ¨¡æ€èƒ½åŠ›

ğŸ”§ åŸºç¡€ç”¨æ³•
-------

### ç®€å•å¯¹è¯

### å®é™…å“åº”ç¤ºä¾‹

åŸºäºæ‚¨çš„æµ‹è¯•ç»“æœï¼Œä»¥ä¸‹æ˜¯å®Œæ•´çš„å“åº”æ ¼å¼ï¼š

```
{
  "id": "resp_6884fcab4930819dbbc02f15cbe63f6c0a92c38ff214d10a",
  "object": "response",
  "created_at": 1753545899,
  "status": "completed",
  "background": false,
  "error": null,
  "incomplete_details": null,
  "instructions": "You are a helpful assistant.",
  "max_output_tokens": null,
  "max_tool_calls": null,
  "model": "gpt-4.1-2025-04-14",
  "output": [
    {
      "id": "msg_6884fcab8f18819dbcdf349f01b424f80a92c38ff214d10a",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "Hello! How can I assist you today?"
        }
      ],
      "role": "assistant"
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "prompt_cache_key": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "safety_identifier": null,
  "service_tier": "default",
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_logprobs": 0,
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 19,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 10,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 29
  },
  "user": null,
  "metadata": {}
}


```

ğŸ“Š è¯·æ±‚å‚æ•°è¯¦è§£
---------

### å¿…éœ€å‚æ•°

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td><code>model</code></td><td>string</td><td>æ¨¡å‹åç§°ï¼Œå¦‚ <code>gpt-4.1</code>, <code>o3</code></td></tr><tr><td><code>input</code></td><td>string</td><td>ç”¨æˆ·è¾“å…¥å†…å®¹</td></tr></tbody></table>

### å¯é€‰å‚æ•°

<table><thead><tr><th>å‚æ•°</th><th>ç±»å‹</th><th>é»˜è®¤å€¼</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td><code>instructions</code></td><td>string</td><td>null</td><td>ç³»ç»ŸæŒ‡ä»¤ï¼Œå®šä¹‰åŠ©æ‰‹è¡Œä¸º</td></tr><tr><td><code>previous_response_id</code></td><td>string</td><td>null</td><td>ä¸Šä¸€ä¸ªå“åº”çš„ IDï¼Œç”¨äºç»´æŠ¤ä¸Šä¸‹æ–‡</td></tr><tr><td><code>temperature</code></td><td>float</td><td>1.0</td><td>æ§åˆ¶è¾“å‡ºéšæœºæ€§ (0-2)</td></tr><tr><td><code>max_output_tokens</code></td><td>int</td><td>null</td><td>æœ€å¤§è¾“å‡ºä»¤ç‰Œæ•°</td></tr><tr><td><code>tools</code></td><td>array</td><td>[]</td><td>å¯ç”¨å·¥å…·åˆ—è¡¨</td></tr><tr><td><code>tool_choice</code></td><td>string</td><td>â€autoâ€</td><td>å·¥å…·é€‰æ‹©ç­–ç•¥</td></tr><tr><td><code>parallel_tool_calls</code></td><td>boolean</td><td>true</td><td>æ˜¯å¦å…è®¸å¹¶è¡Œå·¥å…·è°ƒç”¨</td></tr><tr><td><code>store</code></td><td>boolean</td><td>true</td><td>æ˜¯å¦å­˜å‚¨å¯¹è¯ç”¨äºè®­ç»ƒ</td></tr><tr><td><code>metadata</code></td><td>object</td><td></td><td>è‡ªå®šä¹‰å…ƒæ•°æ®</td></tr></tbody></table>

ğŸ› ï¸ å†…ç½®å·¥å…·æ”¯æŒ
----------

### 1. å‡½æ•°è°ƒç”¨

```
response = client.responses.create(
    model="gpt-4.1",
    input="What's the weather like in Beijing?",
    instructions="You are a helpful weather assistant.",
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get current weather for a city",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {
                            "type": "string",
                            "description": "City name"
                        }
                    },
                    "required": ["city"]
                }
            }
        }
    ]
)


```

### 2. ä»£ç è§£é‡Šå™¨

```
response = client.responses.create(
    model="gpt-4.1", 
    input="Create a chart showing sales data: Jan:100, Feb:150, Mar:120",
    instructions="You are a data analyst. Use code interpreter to create visualizations.",
    tools=[{"type": "code_interpreter"}]
)


```

### 3. æ–‡ä»¶æœç´¢

```
response = client.responses.create(
    model="gpt-4.1",
    input="Search for information about quarterly reports",
    instructions="You are a document analyst.",
    tools=[{"type": "file_search"}]
)


```

ğŸ”„ çŠ¶æ€ç®¡ç†
-------

### ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡

```
# ç¬¬ä¸€è½®å¯¹è¯
response1 = client.responses.create(
    model="gpt-4.1",
    input="My name is Alice. Please remember this.",
    instructions="You are a helpful assistant with good memory."
)

# ç¬¬äºŒè½®å¯¹è¯ - ä½¿ç”¨ previous_response_id ç»´æŠ¤ä¸Šä¸‹æ–‡
response2 = client.responses.create(
    model="gpt-4.1", 
    input="What's my name?",
    instructions="You are a helpful assistant with good memory.",
    previous_response_id=response1.id
)

print(response2.output[0].content[0].text)  # åº”è¯¥å›ç­” "Alice"


```

### å¤šè½®å·¥å…·è°ƒç”¨

```
def multi_turn_conversation():
    response_id = None
    
    for user_input in ["What's 2+2?", "Now multiply that by 3", "And divide by 2"]:
        response = client.responses.create(
            model="o3",
            input=user_input,
            instructions="You are a math tutor. Show your reasoning.",
            previous_response_id=response_id,
            tools=[{"type": "code_interpreter"}]
        )
        
        print(f"User: {user_input}")
        print(f"Assistant: {response.output[0].content[0].text}")
        
        response_id = response.id  # ä¿æŒä¸Šä¸‹æ–‡


```

ğŸ“ˆ æ¨ç†æ¨¡å‹ç‰¹æ€§
---------

### O3/O4-mini æ¨ç†ä¿æŒ

æ¨ç†æ¨¡å‹åœ¨ Responses API ä¸­å…·æœ‰ç‰¹æ®Šä¼˜åŠ¿ï¼š

```
# ä½¿ç”¨ O3 è¿›è¡Œå¤æ‚æ¨ç†
response = client.responses.create(
    model="o3",
    input="Solve this step by step: If a train travels 120km in 2 hours, then speeds up 20% for the next hour, how far did it travel in total?",
    instructions="Think through this problem step by step, showing all reasoning."
)

# æŸ¥çœ‹æ¨ç†è¿‡ç¨‹
reasoning_tokens = response.usage.output_tokens_details.reasoning_tokens
print(f"Reasoning tokens used: {reasoning_tokens}")

# ç»§ç»­å¯¹è¯ï¼Œæ¨ç†ä¸Šä¸‹æ–‡ä¼šä¿æŒ
follow_up = client.responses.create(
    model="o3",
    input="Now what if the train slowed down 10% in the fourth hour?",
    previous_response_id=response.id
)


```

ğŸ†š ä¸ Chat Completions å¯¹æ¯”
------------------------

<table><thead><tr><th>ç‰¹æ€§</th><th>Chat Completions</th><th>Responses API</th></tr></thead><tbody><tr><td><strong>åŸºç¡€å¯¹è¯</strong></td><td>âœ… æ”¯æŒ</td><td>âœ… æ”¯æŒ</td></tr><tr><td><strong>æµå¼å“åº”</strong></td><td>âœ… æ”¯æŒ</td><td>âœ… æ”¯æŒ</td></tr><tr><td><strong>å‡½æ•°è°ƒç”¨</strong></td><td>âœ… æ”¯æŒ</td><td>âœ… å¢å¼ºæ”¯æŒ</td></tr><tr><td><strong>å†…ç½®å·¥å…·</strong></td><td>âŒ ä¸æ”¯æŒ</td><td>âœ… ä¸°å¯Œå·¥å…·</td></tr><tr><td><strong>çŠ¶æ€ç®¡ç†</strong></td><td>âŒ æ— çŠ¶æ€</td><td>âœ… æœ‰çŠ¶æ€</td></tr><tr><td><strong>æ¨ç†ä¿æŒ</strong></td><td>âŒ ä¸æ”¯æŒ</td><td>âœ… O3/O4 æ”¯æŒ</td></tr><tr><td><strong>æ–‡ä»¶æœç´¢</strong></td><td>âŒ ä¸æ”¯æŒ</td><td>âœ… æ”¯æŒ</td></tr><tr><td><strong>ä»£ç è§£é‡Šå™¨</strong></td><td>âŒ ä¸æ”¯æŒ</td><td>âœ… æ”¯æŒ</td></tr></tbody></table>

### è¿ç§»ç¤ºä¾‹

ä» Chat Completions è¿ç§»åˆ° Responses APIï¼š

ğŸ”§ é«˜çº§åŠŸèƒ½
-------

### å¹¶è¡Œå·¥å…·è°ƒç”¨

```
response = client.responses.create(
    model="gpt-4.1",
    input="Get weather for Beijing and Shanghai, then calculate travel time between them",
    instructions="You are a travel assistant.",
    parallel_tool_calls=True,
    tools=[
        {"type": "function", "function": {"name": "get_weather", ...}},
        {"type": "function", "function": {"name": "calculate_distance", ...}}
    ]
)


```

### è¾“å‡ºæ ¼å¼æ§åˆ¶

```
response = client.responses.create(
    model="gpt-4.1",
    input="Summarize this data in JSON format",
    instructions="Always respond in valid JSON.",
    text={
        "format": {
            "type": "json_object"
        }
    }
)


```

### æ¨ç†åŠªåŠ›æ§åˆ¶ï¼ˆO3 ç³»åˆ—ï¼‰

```
response = client.responses.create(
    model="o3",
    input="Solve this complex physics problem",
    instructions="Think carefully and show detailed reasoning.",
    reasoning={
        "effort": "high"  # low, medium, high
    }
)


```

ğŸ“Š å“åº”å­—æ®µè¯¦è§£
---------

### æ ¸å¿ƒå­—æ®µ

<table><thead><tr><th>å­—æ®µ</th><th>ç±»å‹</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>å“åº”å”¯ä¸€æ ‡è¯†ç¬¦</td></tr><tr><td><code>object</code></td><td>string</td><td>å›ºå®šä¸º â€œresponseâ€</td></tr><tr><td><code>created_at</code></td><td>integer</td><td>åˆ›å»ºæ—¶é—´æˆ³</td></tr><tr><td><code>status</code></td><td>string</td><td>çŠ¶æ€ï¼šcompleted/failed/in_progress</td></tr><tr><td><code>model</code></td><td>string</td><td>å®é™…ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬</td></tr><tr><td><code>output</code></td><td>array</td><td>è¾“å‡ºæ¶ˆæ¯æ•°ç»„</td></tr><tr><td><code>usage</code></td><td>object</td><td>Token ä½¿ç”¨ç»Ÿè®¡</td></tr></tbody></table>

### è¾“å‡ºæ¶ˆæ¯æ ¼å¼

```
{
  "id": "msg_xxx",
  "type": "message",
  "status": "completed",
  "content": [
    {
      "type": "output_text",
      "text": "å“åº”å†…å®¹",
      "annotations": [],
      "logprobs": []
    }
  ],
  "role": "assistant"
}


```

### ä½¿ç”¨ç»Ÿè®¡

```
{
  "usage": {
    "input_tokens": 19,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 10,
    "output_tokens_details": {
      "reasoning_tokens": 0  // ä»…æ¨ç†æ¨¡å‹
    },
    "total_tokens": 29
  }
}


```

ğŸš¨ é”™è¯¯å¤„ç†
-------

### æ ‡å‡†é”™è¯¯æ ¼å¼

```
{
  "error": {
    "type": "invalid_request_error",
    "code": "model_not_supported",
    "message": "The model 'gpt-3.5-turbo' is not supported for the responses endpoint.",
    "param": "model"
  }
}


```

### å¸¸è§é”™è¯¯

<table><thead><tr><th>é”™è¯¯ç </th><th>è¯´æ˜</th><th>è§£å†³æ–¹æ¡ˆ</th></tr></thead><tbody><tr><td><code>model_not_supported</code></td><td>æ¨¡å‹ä¸æ”¯æŒ Responses API</td><td>ä½¿ç”¨æ”¯æŒçš„æ–°æ¨¡å‹</td></tr><tr><td><code>invalid_previous_response_id</code></td><td>æ— æ•ˆçš„ä¸Šä¸€ä¸ªå“åº” ID</td><td>æ£€æŸ¥å“åº” ID æ˜¯å¦æ­£ç¡®</td></tr><tr><td><code>tool_not_available</code></td><td>å·¥å…·ä¸å¯ç”¨</td><td>æ£€æŸ¥å·¥å…·é…ç½®</td></tr><tr><td><code>max_tokens_exceeded</code></td><td>è¶…å‡ºä»¤ç‰Œé™åˆ¶</td><td>å‡å°‘è¾“å…¥æˆ–è®¾ç½® max_output_tokens</td></tr></tbody></table>

ğŸ’¡ æœ€ä½³å®è·µ
-------

### 1. çŠ¶æ€ç®¡ç†ç­–ç•¥

```
class ConversationManager:
    def __init__(self, model="gpt-4.1", instructions="You are a helpful assistant."):
        self.model = model
        self.instructions = instructions
        self.last_response_id = None
    
    def send_message(self, input_text, tools=None):
        response = client.responses.create(
            model=self.model,
            input=input_text,
            instructions=self.instructions,
            previous_response_id=self.last_response_id,
            tools=tools or []
        )
        
        self.last_response_id = response.id
        return response.output[0].content[0].text
    
    def reset_conversation(self):
        self.last_response_id = None

# ä½¿ç”¨ç¤ºä¾‹
conv = ConversationManager()
print(conv.send_message("Hello, I'm Alice"))
print(conv.send_message("What's my name?"))  # ä¼šè®°ä½æ˜¯ Alice


```

### 2. å·¥å…·è°ƒç”¨ä¼˜åŒ–

```
def smart_tool_calling(user_input):
    # æ ¹æ®è¾“å…¥æ™ºèƒ½é€‰æ‹©å·¥å…·
    available_tools = []
    
    if "weather" in user_input.lower():
        available_tools.append(weather_tool)
    if "calculate" in user_input.lower():
        available_tools.append(calculator_tool)
    if "search" in user_input.lower():
        available_tools.append(search_tool)
    
    response = client.responses.create(
        model="gpt-4.1",
        input=user_input,
        instructions="Use the appropriate tools to help the user.",
        tools=available_tools,
        tool_choice="auto"
    )
    
    return response


```

### 3. æ¨ç†æ¨¡å‹ä¼˜åŒ–

```
def optimized_reasoning(complex_problem):
    response = client.responses.create(
        model="o3",
        input=complex_problem,
        instructions="Think step by step and show your reasoning process.",
        reasoning={
            "effort": "high"  # å¯¹å¤æ‚é—®é¢˜ä½¿ç”¨é«˜æ¨ç†åŠªåŠ›
        },
        temperature=0.1  # é™ä½éšæœºæ€§ä»¥è·å¾—ä¸€è‡´ç»“æœ
    )
    
    # åˆ†ææ¨ç†ä½¿ç”¨æƒ…å†µ
    reasoning_tokens = response.usage.output_tokens_details.reasoning_tokens
    total_cost = calculate_cost(response.usage)
    
    return {
        "answer": response.output[0].content[0].text,
        "reasoning_tokens": reasoning_tokens,
        "cost": total_cost
    }


```

ğŸ”® æœªæ¥å‘å±•
-------

### å³å°†æ¨å‡ºçš„åŠŸèƒ½

1.  **å®Œæ•´çš„ Assistants API åŠŸèƒ½é›†æˆ**ï¼ˆ2026 å¹´ä¸ŠåŠå¹´ï¼‰
2.  **æ›´å¤šå†…ç½®å·¥å…·**ï¼šWeb æœç´¢ã€è®¡ç®—æœºä½¿ç”¨ç­‰
3.  **æ¨¡å‹ä¸Šä¸‹æ–‡åè®® (MCP) æ”¯æŒ**
4.  **å¢å¼ºçš„å¤šæ¨¡æ€èƒ½åŠ›**

### è¿ç§»æ—¶é—´çº¿

*   **ç°åœ¨**ï¼šå¯ä»¥å¼€å§‹ä½¿ç”¨ Responses API
*   **2026 å¹´ä¸ŠåŠå¹´**ï¼šåŠŸèƒ½å¯¹ç­‰ Assistants API
*   **2026 å¹´**ï¼šAssistants API å¼ƒç”¨å…¬å‘Š
*   **2027 å¹´**ï¼šå®Œå…¨è¿ç§»åˆ° Responses API

éœ€è¦æ›´å¤šå¸®åŠ©ï¼Ÿè¯·è®¿é—® [API æ˜“å®˜ç½‘](https://api.apiyi.com/) æˆ–æŸ¥çœ‹ [OpenAI Responses API å®˜æ–¹æ–‡æ¡£](https://platform.openai.com/docs/api-reference/responses)ã€‚