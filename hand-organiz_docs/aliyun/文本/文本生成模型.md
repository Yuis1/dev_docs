---
url: https://help.aliyun.com/document_detail/2841718.html?mode=pure
title: "多模态输入文本语音生成-文本生成模型-大模型服务平台百炼-阿里云"
captured_at: "2026-01-25T01:23:37.128Z"
---


# 多模态输入文本语音生成-文本生成模型-大模型服务平台百炼-阿里云

文本生成模型能够基于输入的提示词（Prompt）创作出逻辑清晰、连贯的文本。

文本生成模型所需的输入可以是简单的关键词、一句话概述或是更复杂的指令和上下文信息。模型通过分析海量数据学习语言模式，广泛应用于：

- **内容创作**：生成新闻报道、商品介绍及短视频脚本。
- **客户服务**：驱动聊天机器人提供全天候支持，解答常见问题。
- **文本翻译**：实现跨语言的快速精准转换。
- **摘要生成**：提炼长文、报告及邮件的核心内容。
- **法律文档编写**：生成合同模板、法律意见书的基础框架。

更多示例可以参考[文本生成样例](https://bailian.console.aliyun.com/?tab=app#/plugin-market/prompt)。

## 模型选型建议

### 服务地域

阿里云百炼提供[北京](https://bailian.console.aliyun.com/?tab=model#/model-market)地域和[新加坡](https://modelstudio.console.aliyun.com/?tab=doc#/doc/?type=model&url=2840914)地域的模型服务，各地域的API-Key不同，选择邻近地域调用可降低网络延迟。

### 通用模型

通义千问Max、通义千问Plus 和通义千问Flash 均已升级至Qwen3系列，并兼容[OpenAI调用方式](https://help.aliyun.com/zh/model-studio/compatibility-of-openai-with-dashscope#28f6fd00cfp2q)，适用于智能客服、文本创作、内容润色以及摘要总结等多种场景。

- [通义千问Plus](https://help.aliyun.com/zh/model-studio/models#5ef284d4ed42p)：在效果、速度和成本上表现均衡，是多数场景的**推荐选择**。
- [通义千问Max](https://help.aliyun.com/zh/model-studio/models#d4ccf72f23jh9) ：通义千问系列效果最好的模型，适合处理复杂、多步骤任务。
- [通义千问Flash](https://help.aliyun.com/zh/model-studio/models#13ff05e329blt) ：通义千问系列速度最快、成本极低的模型，适用于执行简单任务。

### 特定场景模型

针对明确的业务需求，阿里云百炼提供多种专用优化模型，覆盖[代码能力](https://help.aliyun.com/zh/model-studio/models#d698550551bob)、[长上下文](https://help.aliyun.com/zh/model-studio/models#27b2b3a15d5c6)、[翻译](https://help.aliyun.com/zh/model-studio/models#b51e22f4b036h)、[数据挖掘](https://help.aliyun.com/zh/model-studio/models#531dbf3f1addx)、[法律](https://help.aliyun.com/zh/model-studio/models#f0436273ef1xm)、[意图理解](https://help.aliyun.com/zh/model-studio/models#85209145a5r68)、[角色扮演](https://help.aliyun.com/zh/model-studio/models#083f31bde1lv3)、[深入研究](https://help.aliyun.com/zh/model-studio/models#af665c3673n6e)等领域。

### 多模态模型

- [通义千问VL](https://help.aliyun.com/zh/model-studio/models#3f1f1c8913fvo)（文+图->文）：具备图像理解能力，支持光学字符识别（OCR）、视觉推理和图文理解等任务。
- [通义千问Omni](https://help.aliyun.com/zh/model-studio/models#5e79514e7cqp5)（全模态-> 文+音）：支持视频、音频、图片、文本等多种数据输入，生成文本和语音输出，以应对跨模态复杂任务。
- [语音识别模型](https://help.aliyun.com/zh/model-studio/models#696c1bf328gf9)（音->文）：识别并转写音频中的语音内容，支持中文（含粤语等各种方言）、英文、日语、韩语等。

### 第三方模型

阿里云百炼支持 [DeepSeek](https://help.aliyun.com/zh/model-studio/minimax-llm-api)、[Kimi](https://help.aliyun.com/zh/model-studio/models#2363cbf60fe6m)、[GLM](https://help.aliyun.com/zh/model-studio/models#059d6a5d1chfp)等众多知名的第三方大语言模型，完整模型列表请参考[文本生成-第三方模型](https://help.aliyun.com/zh/model-studio/models#774b4cf48dtbp)。

## 核心概念

文本生成模型的输入为提示词（Prompt），它由一个或多个消息（Message）对象构成。每条消息由角色（Role）和内容（Content）组成，具体为：

- **系统消息（System Message）**：设定模型扮演的角色或遵循的指令。若不指定，默认为"You are a helpful assistant"。
- **用户消息（User Message）**：用户向模型提出的问题或输入的指令。
- **助手消息（Assistant Message）**：模型的回复内容。

调用模型时，需构造一个由上述消息对象构成的数组`messages`。一个典型的请求通常由一条定义行为准则的 `system` 消息和一条用户提指令的 `user` 消息组成。

**system消息是可选的，但建议使用它来设定模型的角色和行为准则，以获得更稳定、一致的输出。


 [
 {"role": "system", "content": "你是一个有帮助的助手，需要提供精准、高效且富有洞察力的回应，随时准备协助用户处理各种任务与问题。"},
 {"role": "user", "content": "你是谁？"}
]

 输出的响应对象中会包含模型回复的assistant消息。


 {
 "role": "assistant",
 "content": "你好！我是Qwen，是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字、进行逻辑推理、编程等。我能够理解并生成多种语言，支持多轮对话和复杂任务处理。如果你有任何需要帮助的地方，尽管告诉我！"
}


## 快速开始

API 使用前提：已获取与配置 API Key并完成配置API Key到环境变量。如果通过SDK调用，需要安装 OpenAI 或 DashScope SDK。运行下方代码，开始与 qwen-plus 模型对话。如需获得更高质量的生成结果，可参考深度思考。OpenAI兼容DashScope


 PythonJavaNode.jsGoC#（HTTP）PHP（HTTP）curl


 import os
from openai import OpenAI

try:
 client = OpenAI(
 # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
 api_key=os.getenv("DASHSCOPE_API_KEY"),
 # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
 )

 completion = client.chat.completions.create(
 # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 model="qwen-plus",
 messages=[
 {"role": "system", "content": "You are a helpful assistant."},
 {"role": "user", "content": "你是谁？"},
 ],
 )
 print(completion.choices[0].message.content)
 # 如需查看完整响应，请取消下列注释
 # print(completion.model_dump_json())
except Exception as e:
 print(f"错误信息：{e}")
 print("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code")


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 // 建议 OpenAI Java SDK版本 >= 3.5.0
import com.openai.client.OpenAIClient;
import com.openai.client.okhttp.OpenAIOkHttpClient;
import com.openai.models.chat.completions.ChatCompletion;
import com.openai.models.chat.completions.ChatCompletionCreateParams;

public class Main {
 public static void main(String[] args) {
 try {
 OpenAIClient client = OpenAIOkHttpClient.builder()
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为.apiKey("sk-xxx")
 .apiKey(System.getenv("DASHSCOPE_API_KEY"))
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 .baseUrl("https://dashscope.aliyuncs.com/compatible-mode/v1")
 .build();

 // 创建 ChatCompletion 参数
 ChatCompletionCreateParams params = ChatCompletionCreateParams.builder()
 .model("qwen-plus") // 指定模型
 .addSystemMessage("You are a helpful assistant.")
 .addUserMessage("你是谁？")
 .build();

 // 发送请求并获取响应
 ChatCompletion chatCompletion = client.chat().completions().create(params);
 String content = chatCompletion.choices().get(0).message().content().orElse("未返回有效内容");
 System.out.println(content);
 // 如需查看完整响应，请取消下列注释
 // System.out.println(chatCompletion);

 } catch (Exception e) {
 System.err.println("错误信息：" + e.getMessage());
 System.out.println("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code");
 }
 }
}


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 // 需要 Node.js v18+，需在 ES Module 环境下运行
import OpenAI from "openai";

const openai = new OpenAI(
 {
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：apiKey: "sk-xxx",
 apiKey: process.env.DASHSCOPE_API_KEY,
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"
 }
);
const completion = await openai.chat.completions.create({
 model: "qwen-plus", //模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 messages: [
 { role: "system", content: "You are a helpful assistant." },
 { role: "user", content: "你是谁？" }
 ],
});
console.log(completion.choices[0].message.content);
// 如需查看完整响应，请取消下列注释
// console.log(JSON.stringify(completion, null, 4));


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 // OpenAI Go SDK版本不低于 v2.4.0
package main

import (
 "context"
 // 如需查看完整响应，请取消下方及代码末尾的注释
 // "encoding/json"
 "fmt"
 "os"

 "github.com/openai/openai-go/v2"
 "github.com/openai/openai-go/v2/option"
)

func main() {
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：apiKey := "sk-xxx"
 apiKey := os.Getenv("DASHSCOPE_API_KEY")
 client := openai.NewClient(
 option.WithAPIKey(apiKey),
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 option.WithBaseURL("https://dashscope.aliyuncs.com/compatible-mode/v1"),
 )
 chatCompletion, err := client.Chat.Completions.New(
 context.TODO(), openai.ChatCompletionNewParams{
 Messages: []openai.ChatCompletionMessageParamUnion{
 openai.SystemMessage("You are a helpful assistant."),
 openai.UserMessage("你是谁？"),
 },
 Model: "qwen-plus",
 },
 )

 if err != nil {
 fmt.Fprintf(os.Stderr, "请求失败: %v\n", err)
 // 更多错误信息，请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code
 os.Exit(1)
 }

 if len(chatCompletion.Choices) > 0 {
 fmt.Println(chatCompletion.Choices[0].Message.Content)
 }
 // 如需查看完整响应，请取消下列注释
 // jsonData, _ := json.MarshalIndent(chatCompletion, "", " ")
 // fmt.Println(string(jsonData))

}


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 using System.Net.Http.Headers;
using System.Text;
using System.Text.Json;

class Program
{
 private static readonly HttpClient httpClient = new HttpClient();

 static async Task Main(string[] args)
 {
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：string? apiKey = "sk-xxx";
 string? apiKey = Environment.GetEnvironmentVariable("DASHSCOPE_API_KEY");
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions
 string url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions";
 // 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 string jsonContent = @"{
 ""model"": ""qwen-plus"",
 ""messages"": [
 {
 ""role"": ""system"",
 ""content"": ""You are a helpful assistant.""
 },
 {
 ""role"": ""user"",
 ""content"": ""你是谁？""
 }
 ]
 }";

 string result = await SendPostRequestAsync(url, jsonContent, apiKey);

 // 如需查看完整响应，请取消下列注释
 // Console.WriteLine(result);

 // 解析JSON并只输出content部分
 using JsonDocument doc = JsonDocument.Parse(result);
 JsonElement root = doc.RootElement;

 if (root.TryGetProperty("choices", out JsonElement choices) &&
 choices.GetArrayLength() > 0)
 {
 JsonElement firstChoice = choices[0];
 if (firstChoice.TryGetProperty("message", out JsonElement message) &&
 message.TryGetProperty("content", out JsonElement content))
 {
 Console.WriteLine(content.GetString());
 }
 }
 }

 private static async Task<string> SendPostRequestAsync(string url, string jsonContent, string apiKey)
 {
 using (var content = new StringContent(jsonContent, Encoding.UTF8, "application/json"))
 {
 httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", apiKey);
 httpClient.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("application/json"));
 HttpResponseMessage response = await httpClient.PostAsync(url, content);
 if (response.IsSuccessStatusCode)
 {
 return await response.Content.ReadAsStringAsync();
 }
 else
 {
 // 更多错误信息，请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code
 return $"请求失败: {response.StatusCode}";
 }
 }
 }
}


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 <?php
// 设置请求的URL
// 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions
$url = 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions';
// 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
// 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：$apiKey = "sk-xxx";
$apiKey = getenv('DASHSCOPE_API_KEY');
// 设置请求头
$headers = [
 'Authorization: Bearer '.$apiKey,
 'Content-Type: application/json'
];
// 设置请求体
$data = [
 // 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 "model" => "qwen-plus",
 "messages" => [
 [
 "role" => "system",
 "content" => "You are a helpful assistant."
 ],
 [
 "role" => "user",
 "content" => "你是谁？"
 ]
 ]
];
// 初始化cURL会话
$ch = curl_init();
// 设置cURL选项
curl_setopt($ch, CURLOPT_URL, $url);
curl_setopt($ch, CURLOPT_POST, true);
curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
// 执行cURL会话
$response = curl_exec($ch);
// 检查是否有错误发生
// 更多错误信息，请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code
if (curl_errno($ch)) {
 echo 'Curl error: ' . curl_error($ch);
}
// 关闭cURL资源
curl_close($ch);
// 输出响应结果
$dataObject = json_decode($response);
$content = $dataObject->choices[0]->message->content;
echo $content;
// 如需查看完整响应，请取消下列注释
//echo $response;
?>


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！

 以下为北京地域base_url，若使用新加坡地域的模型，需将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions各地域的API Key不同，请参见 获取与配置 API Key。


 curl -X POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \
-H "Authorization: Bearer $DASHSCOPE_API_KEY" \
-H "Content-Type: application/json" \
-d '{
 "model": "qwen-plus",
 "messages": [
 {
 "role": "system",
 "content": "You are a helpful assistant."
 },
 {
 "role": "user",
 "content": "你是谁？"
 }
 ]
}'


#### 返回结果


 {
 "choices": [
 {
 "message": {
 "role": "assistant",
 "content": "我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！"
 },
 "finish_reason": "stop",
 "index": 0,
 "logprobs": null
 }
 ],
 "object": "chat.completion",
 "usage": {
 "prompt_tokens": 26,
 "completion_tokens": 66,
 "total_tokens": 92
 },
 "created": 1726127645,
 "system_fingerprint": null,
 "model": "qwen-plus",
 "id": "chatcmpl-81951b98-28b8-9659-ab07-xxxxxx"
}

 PythonJavaNode.js（HTTP）Go（HTTP）C#（HTTP）PHP（HTTP）curl


 import json
import os
from dashscope import Generation
import dashscope


# 若使用新加坡地域的模型，请释放下列注释
# dashscope.base_http_api_url = "https://dashscope-intl.aliyuncs.com/api/v1"

messages = [
 {"role": "system", "content": "You are a helpful assistant."},
 {"role": "user", "content": "你是谁？"},
]
response = Generation.call(
 # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key = "sk-xxx",
 api_key=os.getenv("DASHSCOPE_API_KEY"),
 model="qwen-plus",
 messages=messages,
 result_format="message",
)

if response.status_code == 200:
 print(response.output.choices[0].message.content)
 # 如需查看完整响应，请取消下列注释
 # print(json.dumps(response, default=lambda o: o.__dict__, indent=4))
else:
 print(f"HTTP返回码：{response.status_code}")
 print(f"错误码：{response.code}")
 print(f"错误信息：{response.message}")
 print("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code")


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 import java.util.Arrays;
import java.lang.System;
import com.alibaba.dashscope.aigc.generation.Generation;
import com.alibaba.dashscope.aigc.generation.GenerationParam;
import com.alibaba.dashscope.aigc.generation.GenerationResult;
import com.alibaba.dashscope.common.Message;
import com.alibaba.dashscope.common.Role;
import com.alibaba.dashscope.exception.ApiException;
import com.alibaba.dashscope.exception.InputRequiredException;
import com.alibaba.dashscope.exception.NoApiKeyException;
import com.alibaba.dashscope.protocol.Protocol;
import com.alibaba.dashscope.utils.JsonUtils;

public class Main {
 public static GenerationResult callWithMessage() throws ApiException, NoApiKeyException, InputRequiredException {
 // 以下为北京地域url，若使用新加坡地域的模型，需将url替换为：https://dashscope-intl.aliyuncs.com/api/v1
 Generation gen = new Generation(Protocol.HTTP.getValue(), "https://dashscope.aliyuncs.com/api/v1");
 Message systemMsg = Message.builder()
 .role(Role.SYSTEM.getValue())
 .content("You are a helpful assistant.")
 .build();
 Message userMsg = Message.builder()
 .role(Role.USER.getValue())
 .content("你是谁？")
 .build();
 GenerationParam param = GenerationParam.builder()
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：.apiKey("sk-xxx")
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 .apiKey(System.getenv("DASHSCOPE_API_KEY"))
 .model("qwen-plus")
 .messages(Arrays.asList(systemMsg, userMsg))
 .resultFormat(GenerationParam.ResultFormat.MESSAGE)
 .build();
 return gen.call(param);
 }
 public static void main(String[] args) {
 try {
 GenerationResult result = callWithMessage();
 System.out.println(result.getOutput().getChoices().get(0).getMessage().getContent());
 // 如需查看完整响应，请取消下列注释
 // System.out.println(JsonUtils.toJson(result));
 } catch (ApiException | NoApiKeyException | InputRequiredException e) {
 System.err.println("错误信息："+e.getMessage());
 System.out.println("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code");
 }
 }
}


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 // 需要 Node.js v18+
// 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
// 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：const apiKey = "sk-xxx";
const apiKey = process.env.DASHSCOPE_API_KEY;

const data = {
 model: "qwen-plus",
 input: {
 messages: [
 {
 role: "system",
 content: "You are a helpful assistant."
 },
 {
 role: "user",
 content: "你是谁？"
 }
 ]
 },
 parameters: {
 result_format: "message"
 }
};

async function callApi() {
 try {
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text-generation/generation
 const response = await fetch('https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation', {
 method: 'POST',
 headers: {
 'Authorization': `Bearer ${apiKey}`,
 'Content-Type': 'application/json'
 },
 body: JSON.stringify(data)
 });

 const result = await response.json();
 console.log(result.output.choices[0].message.content);
 // 如需查看完整响应，请取消下列注释
 // console.log(JSON.stringify(result));
 } catch (error) {
 // 更多错误信息，请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code
 console.error('调用失败:', error.message);
 }
}

callApi();


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 package main

import (
 "bytes"
 "encoding/json"
 "fmt"
 "io"
 "log"
 "net/http"
 "os"
)

func main() {
 requestBody := map[string]interface{}{
 "model": "qwen-plus",
 "input": map[string]interface{}{
 "messages": []map[string]string{
 {
 "role": "system",
 "content": "You are a helpful assistant.",
 },
 {
 "role": "user",
 "content": "你是谁？",
 },
 },
 },
 "parameters": map[string]string{
 "result_format": "message",
 },
 }

 // 序列化为 JSON
 jsonData, _ := json.Marshal(requestBody)

 // 创建 HTTP 客户端和请求
 client := &http.Client{}
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text-generation/generation
 req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonData))

 // 设置请求头
 apiKey := os.Getenv("DASHSCOPE_API_KEY")
 req.Header.Set("Authorization", "Bearer "+apiKey)
 req.Header.Set("Content-Type", "application/json")

 // 发送请求
 resp, err := client.Do(req)
 if err != nil {
 log.Fatal(err)
 }
 defer resp.Body.Close()

 // 读取响应体
 bodyText, _ := io.ReadAll(resp.Body)

 // 解析JSON并输出content内容
 var result map[string]interface{}
 json.Unmarshal(bodyText, &result)
 content := result["output"].(map[string]interface{})["choices"].([]interface{})[0].(map[string]interface{})["message"].(map[string]interface{})["content"].(string)
 fmt.Println(content)

 // 如需查看完整响应，请取消下列注释
 // fmt.Printf("%s\n", bodyText)
}


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！


 using System.Net.Http.Headers;
using System.Text;

class Program
{
 private static readonly HttpClient httpClient = new HttpClient();

 static async Task Main(string[] args)
 {
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：string? apiKey = "sk-xxx";
 string? apiKey = Environment.GetEnvironmentVariable("DASHSCOPE_API_KEY");
 // 设置请求 URL 和内容
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text-generation/generation
 string url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation";
 string jsonContent = @"{
 ""model"": ""qwen-plus"",
 ""input"": {
 ""messages"": [
 {
 ""role"": ""system"",
 ""content"": ""You are a helpful assistant.""
 },
 {
 ""role"": ""user"",
 ""content"": ""你是谁？""
 }
 ]
 },
 ""parameters"": {
 ""result_format"": ""message""
 }
 }";

 // 发送请求并获取响应
 string result = await SendPostRequestAsync(url, jsonContent, apiKey);
 var jsonResult = System.Text.Json.JsonDocument.Parse(result);
 var content = jsonResult.RootElement.GetProperty("output").GetProperty("choices")[0].GetProperty("message").GetProperty("content").GetString();
 Console.WriteLine(content);
 // 如需查看完整响应，请取消下列注释
 // Console.WriteLine(result);
 }

 private static async Task<string> SendPostRequestAsync(string url, string jsonContent, string apiKey)
 {
 using (var content = new StringContent(jsonContent, Encoding.UTF8, "application/json"))
 {
 // 设置请求头
 httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", apiKey);
 httpClient.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("application/json"));

 // 发送请求并获取响应
 HttpResponseMessage response = await httpClient.PostAsync(url, content);

 // 处理响应
 if (response.IsSuccessStatusCode)
 {
 return await response.Content.ReadAsStringAsync();
 }
 else
 {
 return $"请求失败: {response.StatusCode}";
 }
 }
 }
}


#### 返回结果


 {
 "output": {
 "choices": [
 {
 "finish_reason": "stop",
 "message": {
 "role": "assistant",
 "content": "我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！"
 }
 }
 ]
 },
 "usage": {
 "total_tokens": 92,
 "output_tokens": 66,
 "input_tokens": 26
 },
 "request_id": "09dceb20-ae2e-999b-85f9-xxxxxx"
}


 <?php
// 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text-generation/generation
$url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation";
// 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
// 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：$apiKey = "sk-xxx";
$apiKey = getenv('DASHSCOPE_API_KEY');

$data = [
 "model" => "qwen-plus",
 "input" => [
 "messages" => [
 [
 "role" => "system",
 "content" => "You are a helpful assistant."
 ],
 [
 "role" => "user",
 "content" => "你是谁？"
 ]
 ]
 ],
 "parameters" => [
 "result_format" => "message"
 ]
];

$jsonData = json_encode($data);

$ch = curl_init($url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch, CURLOPT_POST, true);
curl_setopt($ch, CURLOPT_POSTFIELDS, $jsonData);
curl_setopt($ch, CURLOPT_HTTPHEADER, [
 "Authorization: Bearer $apiKey",
 "Content-Type: application/json"
]);

$response = curl_exec($ch);
$httpCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);

if ($httpCode == 200) {
 $jsonResult = json_decode($response, true);
 $content = $jsonResult['output']['choices'][0]['message']['content'];
 echo $content;
 // 如需查看完整响应，请取消下列注释
 // echo "模型响应: " . $response;
} else {
 echo "请求错误: " . $httpCode . " - " . $response;
}

curl_close($ch);
?>


#### 返回结果


 我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！

 以下为北京地域base_url，若使用新加坡地域的模型，需将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text-generation/generation各地域的API-Key不同，请参见 获取与配置 API Key。


 curl --location "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation" \
--header "Authorization: Bearer $DASHSCOPE_API_KEY" \
--header "Content-Type: application/json" \
--data '{
 "model": "qwen-plus",
 "input":{
 "messages":[
 {
 "role": "system",
 "content": "You are a helpful assistant."
 },
 {
 "role": "user",
 "content": "你是谁？"
 }
 ]
 },
 "parameters": {
 "result_format": "message"
 }
}'


#### 返回结果


 {
 "output": {
 "choices": [
 {
 "finish_reason": "stop",
 "message": {
 "role": "assistant",
 "content": "我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！"
 }
 }
 ]
 },
 "usage": {
 "total_tokens": 92,
 "output_tokens": 66,
 "input_tokens": 26
 },
 "request_id": "09dceb20-ae2e-999b-85f9-xxxxxx"
}


## 图像、视频数据处理

多模态模型支持处理图像、视频等非文本数据，可用于视觉问答、事件检测等任务。其调用方式与纯文本模型主要有以下不同：用户消息（user message）的构造方式**：多模态模型的用户消息不仅包含文本，还包含图片、音频等多模态信息。

**DashScope SDK接口：**使用 DashScope Python SDK 时，需调用 `MultiModalConversation` 接口；使用DashScope Java SDK 时，需调用 `MultiModalConversation` 类。

**图片、视频文件限制请参见视觉理解。OpenAI兼容DashScope


 PythonNode.jscurl


 from openai import OpenAI
import os

client = OpenAI(
 # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx"
 api_key=os.getenv("DASHSCOPE_API_KEY"),
 # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
messages = [
 {
 "role": "user",
 "content": [
 {
 "type": "image_url",
 "image_url": {
 "url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"
 },
 },
 {"type": "text", "text": "请问图片展现了有哪些商品？"},
 ],
 }
]
completion = client.chat.completions.create(
 model="qwen3-vl-plus", # 可按需更换为其它多模态模型，并修改相应的 messages
 messages=messages,
)
print(completion.choices[0].message.content)


 import OpenAI from "openai";

const openai = new OpenAI(
 {
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用百炼API Key将下行替换为：apiKey: "sk-xxx",
 apiKey: process.env.DASHSCOPE_API_KEY,
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"
 }
);

let messages = [
 {
 role: "user",
 content: [
 { type: "image_url", image_url: { "url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png" } },
 { type: "text", text: "请问图片展现了有哪些商品？" },
 ]
 }]
async function main() {
 let response = await openai.chat.completions.create({
 model: "qwen3-vl-plus", // 可按需更换为其它多模态模型，并修改相应的 messages
 messages: messages
 });
 console.log(response.choices[0].message.content);
}

main()

 以下为北京地域base_url，若使用新加坡地域的模型，需将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions各地域的API Key不同，请参见 获取与配置 API Key。


 curl -X POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \
-H "Authorization: Bearer $DASHSCOPE_API_KEY" \
-H 'Content-Type: application/json' \
-d '{
 "model": "qwen3-vl-plus",
 "messages": [
 {
 "role": "user",
 "content": [
 {
 "type": "image_url",
 "image_url": {
 "url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"
 }
 },
 {
 "type": "text",
 "text": "请问图片展现了有哪些商品？"
 }
 ]
 }
 ]
}'

 PythonJavacurl


 import os
import dashscope
from dashscope import MultiModalConversation


# 若使用新加坡地域的模型，请取消下列注释
# dashscope.base_http_api_url = "https://dashscope-intl.aliyuncs.com/api/v1"

messages = [
 {
 "role": "user",
 "content": [
 {
 "image": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"
 },
 {"text": "请问图片展现了有哪些商品？"},
 ],
 }
]
response = MultiModalConversation.call(
 # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
 # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 api_key=os.getenv('DASHSCOPE_API_KEY'),
 model='qwen3-vl-plus', # 可按需更换为其它多模态模型，并修改相应的 messages
 messages=messages)
print(response.output.choices[0].message.content[0]['text'])


 import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversation;
import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversationParam;
import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversationResult;
import com.alibaba.dashscope.common.MultiModalMessage;
import com.alibaba.dashscope.common.Role;
import com.alibaba.dashscope.exception.ApiException;
import com.alibaba.dashscope.exception.NoApiKeyException;
import com.alibaba.dashscope.exception.UploadFileException;
import com.alibaba.dashscope.utils.Constants;

public class Main {
 // 若使用新加坡地域的模型，请取消下列注释
 // static {Constants.baseHttpApiUrl="https://dashscope-intl.aliyuncs.com/api/v1";}

 private static final String modelName = "qwen3-vl-plus"; // 可按需更换为其它多模态模型，并修改相应的 messages

 public static void MultiRoundConversationCall() throws ApiException, NoApiKeyException, UploadFileException {
 MultiModalConversation conv = new MultiModalConversation();
 MultiModalMessage userMessage = MultiModalMessage.builder().role(Role.USER.getValue())
 .content(Arrays.asList(Collections.singletonMap("image", "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"),
 Collections.singletonMap("text", "请问图片展现了有哪些商品？"))).build();
 List<MultiModalMessage> messages = new ArrayList<>();
 messages.add(userMessage);
 MultiModalConversationParam param = MultiModalConversationParam.builder()
 // 若没有配置环境变量，请用百炼API Key将下行替换为：.apiKey("sk-xxx")
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 .apiKey(System.getenv("DASHSCOPE_API_KEY"))
 .model(modelName)
 .messages(messages)
 .build();
 MultiModalConversationResult result = conv.call(param);
 System.out.println(result.getOutput().getChoices().get(0).getMessage().getContent().get(0).get("text")); // add the result to conversation
 }

 public static void main(String[] args) {
 try {
 MultiRoundConversationCall();
 } catch (ApiException | NoApiKeyException | UploadFileException e) {
 System.out.println(e.getMessage());
 }
 System.exit(0);
 }
}

 以下为北京地域base_url，若使用新加坡地域的模型，需将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation各地域的API-Key不同，请参见 获取与配置 API Key。


 curl -X POST https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation \
-H "Authorization: Bearer $DASHSCOPE_API_KEY" \
-H 'Content-Type: application/json' \
-d '{
 "model": "qwen3-vl-plus",
 "input":{
 "messages":[
 {
 "role": "user",
 "content": [
 {"image": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"},
 {"text": "请问图片展现了有哪些商品？"}
 ]
 }
 ]
 }
}'


## 异步调用模型

调用异步接口，可有效提升高并发请求的处理效率。OpenAI兼容DashScope


 PythonJava


 import os
import asyncio
from openai import AsyncOpenAI
import platform


# 创建异步客户端实例

client = AsyncOpenAI(
 # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
 api_key=os.getenv("DASHSCOPE_API_KEY"),
 # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)


# 定义异步任务列表

async def task(question):
 print(f"发送问题: {question}")
 response = await client.chat.completions.create(
 messages=[
 {"role": "system", "content": "You are a helpful assistant." },
 {"role": "user", "content": question}
 ],
 model="qwen-plus", # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 )
 print(f"模型回复: {response.choices[0].message.content}")


# 主异步函数

async def main():
 questions = ["你是谁？", "你会什么？", "天气怎么样？"]
 tasks = [task(q) for q in questions]
 await asyncio.gather(*tasks)

if __name__ == '__main__':
 # 设置事件循环策略
 if platform.system() == 'Windows':
 asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
 # 运行主协程
 asyncio.run(main(), debug=False)


 import com.openai.client.OpenAIClientAsync;
import com.openai.client.okhttp.OpenAIOkHttpClientAsync;
import com.openai.models.chat.completions.ChatCompletionCreateParams;

import java.util.Arrays;
import java.util.List;
import java.util.concurrent.CompletableFuture;

public class Main {
 public static void main(String[] args) {
 // 创建 OpenAI 客户端，连接 DashScope 的兼容接口
 OpenAIClientAsync client = OpenAIOkHttpClientAsync.builder()
 // 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
 // 若没有配置环境变量，请用阿里云百炼API Key将下行替换为.apiKey("sk-xxx")
 .apiKey(System.getenv("DASHSCOPE_API_KEY"))
 // 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
 .baseUrl("https://dashscope.aliyuncs.com/compatible-mode/v1")
 .build();

 // 定义问题列表
 List<String> questions = Arrays.asList("你是谁？", "你会什么？", "天气怎么样？");

 // 创建异步任务列表
 CompletableFuture<?>[] futures = questions.stream()
 .map(question -> CompletableFuture.supplyAsync(() -> {
 System.out.println("发送问题: " + question);
 // 创建 ChatCompletion 参数
 ChatCompletionCreateParams params = ChatCompletionCreateParams.builder()
 .model("qwen-plus") // 指定模型
 .addSystemMessage("You are a helpful assistant.")
 .addUserMessage(question)
 .build();

 // 发送异步请求并处理响应
 return client.chat().completions().create(params)
 .thenAccept(chatCompletion -> {
 String content = chatCompletion.choices().get(0).message().content().orElse("无响应内容");
 System.out.println("模型回复: " + content);
 })
 .exceptionally(e -> {
 System.err.println("错误信息：" + e.getMessage());
 System.out.println("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code");
 return null;
 });
 }).thenCompose(future -> future))
 .toArray(CompletableFuture[]::new);

 // 等待所有异步操作完成
 CompletableFuture.allOf(futures).join();
 }
}

 DashScope SDK的文本生成异步调用，目前仅支持Python。


 # DashScope Python SDK版本需要不低于 1.19.0
import asyncio
import platform
from dashscope.aigc.generation import AioGeneration
import os
import dashscope


# 若使用新加坡地域的模型，请释放下列注释
# dashscope.base_http_api_url = "https://dashscope-intl.aliyuncs.com/api/v1"


# 定义异步任务列表

async def task(question):
 print(f"发送问题: {question}")
 response = await AioGeneration.call(
 # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
 api_key=os.getenv("DASHSCOPE_API_KEY"),
 model="qwen-plus", # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
 messages=[{"role": "system", "content": "You are a helpful assistant."},
 {"role": "user", "content": question}],
 result_format="message",
 )
 print(f"模型回复: {response.output.choices[0].message.content}")


# 主异步函数

async def main():
 questions = ["你是谁？", "你会什么？", "天气怎么样？"]
 tasks = [task(q) for q in questions]
 await asyncio.gather(*tasks)

if __name__ == '__main__':
 # 设置事件循环策略
 if platform.system() == 'Windows':
 asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
 # 运行主协程
 asyncio.run(main(), debug=False)


#### 返回结果

由于调用是异步的，响应的返回顺序可能与示例不同。


 发送问题: 你是谁？
发送问题: 你会什么？
发送问题: 天气怎么样？
模型回复: 你好！我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！
模型回复: 您好！我目前无法实时获取天气信息。您可以告诉我您所在的城市或地区，我会尽力为您提供一些通用的天气建议或信息。或者您也可以使用天气应用查看实时天气情况。
模型回复: 我会很多技能，比如：

1. **回答问题**：无论是学术问题、生活常识还是专业知识，我都可以尝试帮你解答。
2. **创作文字**：我可以写故事、公文、邮件、剧本等各类文本。
3. **逻辑推理**：我可以帮助你解决一些逻辑推理问题，比如数学题、谜语等。
4. **编程**：我可以提供编程帮助，包括代码编写、调试和优化。
5. **多语言支持**：我支持多种语言，包括但不限于中文、英文、法语、西班牙语等。
6. **观点表达**：我可以为你提供一些观点和建议，帮助你做出决策。
7. **玩游戏**：我们可以一起玩文字游戏，比如猜谜语、成语接龙等。

如果你有任何具体的需求或问题，欢迎告诉我，我会尽力帮助你！


## 应用于生产环境

### 构建高质量的上下文

向大模型直接输入大量原始数据，会因上下文容量的限制导致成本增加与效果下降。上下文工程（Context Engineering）通过动态加载精准知识，显著提升生成质量与效率。核心技术包括：提示词工程（Prompt Engineering）**：通过设计和优化文本指令（Prompt），可以更精确地引导模型，使其输出更符合预期的结果。若想了解更多，可参考[文生文Prompt指南](https://help.aliyun.com/zh/model-studio/prompt-engineering-guide)、阿里云百炼 [提示词模板](https://bailian.console.aliyun.com/?tab=app#/plugin-market/prompt)页面。

[检索增强生成（RAG）](https://help.aliyun.com/zh/model-studio/rag-knowledge-base)：适用于需要模型依据外部知识库（例如产品文档或技术手册）来回答问题的场景。

[工具调用（Tool）](https://help.aliyun.com/zh/model-studio/tool-calls/)：允许模型获取实时信息（如查询天气、路况）或完成特定操作（如调用API、发送邮件）。

**记忆机制（Memory）**：为模型建立长短期记忆，使其能够理解连续对话的历史信息。

若想系统了解，可参考[阿里云大模型高级工程师ACP认证课程](https://atomgit.com/alibabaclouddocs/aliyun_acp_learning/blob/main/%E5%A4%A7%E6%A8%A1%E5%9E%8BACP%E8%AE%A4%E8%AF%81%E6%95%99%E7%A8%8B/p2_%E6%9E%84%E9%80%A0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/2_1_%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B0%E4%BA%BA%E7%AD%94%E7%96%91%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb)。

### 控制回复多样性

`temperature`****和 `top_p`用于控制生成文本的多样性。数值越高，内容越多样，数值越低，内容越确定。为准确评估参数效果，建议每次只调整一个。

- `**temperature**`：范围 [0, 2)。侧重调整随机性。
- `**top_p**`：范围 [0, 1]。通过概率阈值筛选回复。

以下示例将展示不同参数设置对生成内容的影响。输入提示词为：“写一个三句话的短故事，主角是一只猫和一束阳光。”

- **高多样性**（示例`temperature`=0.9）：适用于需要创意、想象力和新颖表达的场景，如创意写作、头脑风暴或市场营销文案。


 **
 **


```
阳光斜斜地切进窗台，橘猫蹑手蹑脚走近那块发光的方砖，绒毛瞬间被染成熔化的蜜糖。
它伸出前爪轻拍光斑，却像踩进温热的池水般陷了进去，整片阳光顺着肉垫汩汩漫上脊背。
午后忽然变得很重——猫儿蜷在流动的金砂里，听见时光在呼噜声中轻轻融化。

```
- **高确定性**（示例`temperature`=0.1）：适用于要求内容准确、严谨和可预测的场景，如事实问答、代码生成或法律文本。


 **
 **


```
午后，一只老猫蜷在窗台，数着光斑打盹。
阳光轻轻跃过它斑驳的脊背，像在翻阅一本旧相册。
尘埃浮起又落下，仿佛时光低语：你曾年轻，我也炽热。

```


**原理介绍**

 **


**temperature**：

- temperature 越高，Token 概率分布变得更平坦（即高概率 Token 的概率降低，低概率 Token 的概率上升），使得模型在选择下一个 Token 时更加随机。
- temperature 越低，Token 概率分布变得更陡峭（即高概率 Token 被选取的概率更高，低概率 Token 的概率更低），使得模型更倾向于选择高概率的少数 Token。

**top_p**：

top_p 采样是指从最高概率（最核心）的 Token 集合中进行采样。它将所有可能的下一个 Token 按概率从高到低排序，然后从概率最高的 Token 开始累加概率，直至概率总和达到阈值（例如80%，即 top_p=0.8），最后从这些概率最高、概率总和达到阈值的 Token 中随机选择一个用于输出。

- top_p 越高，考虑的 Token 越多，因此生成的文本更多样。
- top_p 越低，考虑的 Token 越少，因此生成的文本更集中和确定。


**不同场景的参数配置示例**

 **


**
 **


```
# 不同场景的推荐参数配置
SCENARIO_CONFIGS = {
 # 创造性写作
 "creative_writing": {
 "temperature": 0.9,
 "top_p": 0.95
 },
 # 代码生成
 "code_generation": {
 "temperature": 0.2,
 "top_p": 0.8
 },
 # 事实性问答
 "factual_qa": {
 "temperature": 0.1,
 "top_p": 0.7
 },
 # 翻译
 "translation": {
 "temperature": 0.3,
 "top_p": 0.8
 }
}


# OpenAI使用示例
# completion = client.chat.completions.create(
# model="qwen-plus",
# messages=[{"role": "user", "content": "写一首关于月亮的诗"}],
# **SCENARIO_CONFIGS["creative_writing"]
# )
# DashScope使用示例
# response = Generation.call(
# # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key = "sk-xxx",
# api_key=os.getenv("DASHSCOPE_API_KEY"),
# model="qwen-plus",
# messages=[{"role": "user", "content": "写一个判断输入n是否是质数的python函数，不要输出非代码内容"}],
# result_format="message",
# **SCENARIO_CONFIGS["code_generation"]
# )

```


### 更多功能

上文介绍了基础的交互方式。针对更复杂的场景，可参考：

- [多轮对话](https://help.aliyun.com/zh/model-studio/multi-round-conversation)：适用于追问、信息采集等需要连续交流的场景。
- [流式输出](https://help.aliyun.com/zh/model-studio/stream)：适用于聊天机器人、实时代码生成等需要即时响应的场景，可以提升用户体验，并避免因响应时间过长导致的超时。
- [深度思考](https://help.aliyun.com/zh/model-studio/deep-thinking)：适用于复杂推理、策略分析等需要更高质量、更具条理的深度回答的场景。
- [结构化输出](https://help.aliyun.com/zh/model-studio/qwen-structured-output)：当需要模型按稳定的 JSON 格式回复，以便于程序调用或数据解析时使用。
- [前缀续写](https://help.aliyun.com/zh/model-studio/partial-mode)：适用于代码补全、长文写作等需要模型接续已有文本的场景。

## API 参考

模型调用的完整参数列表，请参考 [OpenAI 兼容 API 参考](https://help.aliyun.com/zh/model-studio/qwen-api-reference/#d397bcc41eu3q)和[DashScope API 参考](https://help.aliyun.com/zh/model-studio/qwen-api-reference/#69cac67a477k2)。

## 常见问题

### Q：通义千问 API 为何无法分析网页链接？

A：通义千问 API 本身不具备直接访问和解析网页链接的能力，可以通过[Function Calling](https://help.aliyun.com/zh/model-studio/qwen-function-calling)、[MCP](https://help.aliyun.com/zh/model-studio/mcp)等功能，或结合 Python 的 Beautiful Soup 等网页抓取工具读取网页信息。

### Q：网页端通义千问和通义千问 API 的回复为什么不一致？

A：网页端通义千问在通义千问 API 的基础上做了额外的工程优化**，**因此可以达到解析网页、联网搜索、画图、制作 PPT等功能，这些本身并不属于大模型 API 的能力，可以通过[联网搜索](https://help.aliyun.com/zh/model-studio/web-search)、[Function Calling](https://help.aliyun.com/zh/model-studio/qwen-function-calling)、[MCP](https://help.aliyun.com/zh/model-studio/mcp)等功能优化模型的效果。

### Q：如何处理模型超时的情况？

A：使用[流式输出](https://help.aliyun.com/zh/model-studio/stream)可避免超时。

非流式调用若超过 300 秒未完成，服务将中断请求，但返回已生成的内容，且不再报超时错误。此时响应头将包含`x-dashscope-partialresponse: true`，表示返回的是超时前的部分结果。

支持该机制的模型如下：


支持的模型

 **


- qwen-max-2024-09-19 及之后的模型
- qwen-plus-2024-11-25 及之后的模型
- qwen-flash-2025-07-28 及之后的模型
- qwen-turbo-2024-11-01 及之后的模型
- qwen-vl-max-2025-01-25 及之后的模型
- qwen-vl-plus-2025-01-02 及之后的模型
- qwen-long-2025-01-25 及之后的模型
- qwen3 开源模型（qwen3-235b-a22b、qwen3-32b、qwen3-30b-a3b、qwen3-14b、qwen3-8b、qwen3-4b、qwen3-1.7b、qwen3-0.6b）
- qwen2.5开源模型（qwen2.5-14b-instruct-1m、qwen2.5-7b-instruct-1m、qwen2.5-72b-instruct、qwen2.5-32b-instruct、qwen2.5-14b-instruct、qwen2.5-7b-instruct、qwen2.5-3b-instruct、qwen2.5-1.5b-instruct、qwen2.5-0.5b-instruct）


> 若无法获取响应头参数（例如通过 SDK 调用），可通过 `finish_reason`字段辅助判断，若为`null`，表示生成内容不完整（但不一定是触发了超时）。

大模型可续写不完整的内容，详情请参见：[基于不完整输出进行续写](https://help.aliyun.com/zh/model-studio/partial-mode#8cc28acfd7a91)。

> Java SDK 暂不支持前缀续写功能。

### Q：模型能直接生成 Word、Excel、PDF 或 PPT 格式的文件吗？

A：不能。阿里云百炼的文本生成模型仅输出纯文本内容。您需要通过代码或使用第三方库将文本转换为所需格式，或通过阿里云百炼[PPT自动生成应用](https://bailian.console.aliyun.com/?tab=app#/app-market/app-template-experience/assistant/AutoPptGenerator)、[网页端通义千问](https://www.qianwen.com/aippt)等方式进行生成。
