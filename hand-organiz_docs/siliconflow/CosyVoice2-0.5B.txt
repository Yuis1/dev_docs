文本转语音模型
​
1. 使用场景
文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景：
为博客文章提供音频朗读
生成多语言语音内容
支持实时流媒体音频输出
​
2. API 使用指南
端点：/audio/speech，具体使用可参考api文档
主要请求参数：
model：用于语音合成的模型，支持的模型列表。
input：待转换为音频的文本内容。
voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。
speed：可以控制音频速度，float类型，默认值是1.0，可选范围是[0.25,4.0]；
gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是[-10,10]；
response_format：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。
sample_rate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下：
opus: 目前只支持48000hz
wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100
mp3: 支持(32000, 44100), 默认44100
​
2.1 系统预置音色：
目前系统预置了如下 8 种音色：
男生音色：
沉稳男声: alex
低沉男声: benjamin
磁性男声: charles
欢快男声: david
女生音色：
沉稳女声: anna
激情女声: bella
温柔女声: claire
欢快女声: diana
在线试听上述音频。
在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如：
FunAudioLLM/CosyVoice2-0.5B:alex 表示 FunAudioLLM/CosyVoice2-0.5B 模型下的 alex 音色。
​
2.2 用户预置音色：
注意：使用用户预置音色，需要进行实名认证。
​
2.2.1 通过 base64 编码格式上传用户预置音色


import requests
import json

url = "https://api.siliconflow.cn/v1/uploads/audio/voice"
headers = {
    "Authorization": "Bearer your-api-key", # 从 https://cloud.siliconflow.cn/account/ak 获取
    "Content-Type": "application/json"
}
data = {
    "model": "FunAudioLLM/CosyVoice2-0.5B", # 模型名称
    "customName": "your-voice-name", # 用户自定义的音频名称
    "audio": "data:audio/mpeg;base64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD/40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8/Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39/f3+KioqKlZWVlZWfn5+fn6qqqqq1tbW1tb+/v7/KysrKytXV1dXf39/f3+rq6ur19fX19f////", # 参考音频的 base64 编码
    "text": "在一无所知中, 梦里的一天结束了，一个新的轮回便会开始" # 参考音频的文字内容
}

response = requests.post(url, headers=headers, data=json.dumps(data))

# 打印响应状态码和响应内容
print(response.status_code)
print(response.json())  # 如果响应是 JSON 格式
上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。


{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
在请求中使用用户预置音色。
​
2.2.2 通过文件上传用户预置音色

import requests

url = "https://api.siliconflow.cn/v1/uploads/audio/voice"
headers = {
    "Authorization": "Bearer your-api-key" # 从 https://cloud.siliconflow.cn/account/ak 获取
}
files = {
    "file": open("/Users/senseb/Downloads/fish_audio-Alex.mp3", "rb") # 参考音频文件
}
data = {
    "model": "FunAudioLLM/CosyVoice2-0.5B", # 模型名称
    "customName": "your-voice-name", # 参考音频名称
    "text": "在一无所知中, 梦里的一天结束了，一个新的轮回便会开始" # 参考音频的文字内容
}

response = requests.post(url, headers=headers, files=files, data=data)

print(response.status_code)
print(response.json())  # 打印响应内容（如果是JSON格式）
上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。


{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
在请求中使用用户预置音色。
​
2.3 获取用户动态音色列表


import requests
url = "https://api.siliconflow.cn/v1/audio/voice/list"

headers = {
    "Authorization": "Bearer your-api-key" # 从https://cloud.siliconflow.cn/account/ak获取
}
response = requests.get(url, headers=headers)

print(response.status_code)
print(response.json()) # 打印响应内容（如果是JSON格式）
上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。


{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
在请求中使用用户预置音色。
​
2.4 使用用户动态音色
注意：使用用户预置音色，需要进行实名认证。
在请求中使用用户动态音色。
​
2.5 删除用户动态音色

import requests

url = "https://api.siliconflow.cn/v1/audio/voice/deletions"
headers = {
    "Authorization": "Bearer your-api-key",
    "Content-Type": "application/json"
}
payload = {
    "uri": "speech:your-voice-name:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd"
}

response = requests.request("POST", url, json=payload, headers=headers)

print(response.status_code)
print(response.text) #打印响应内容
上述接口请求参数中的 uri 字段，即为自定义音色的 ID。
​
3. 支持模型列表
注意：支持的 TTS 模型可能发生调整，请在「模型广场」筛选“语音”标签 获得当前支持的模型列表。
计费方式：按照输入文本长度对应的 UTF-8 字节 数进行计费，在线字节计数器演示。
​
3.1 FunAudioLLM/CosyVoice2-0.5B 系列模型
跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话）
情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。
细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。
​
3.2 fnlp/MOSS-TTSD-v0.5
高表现力语音：自然对话语调，支持情感表达
双人语音克隆：零样本克隆，自动切换说话人
中英双语支持：流畅混合合成，发音自然
长篇语音生成：低延迟，稳定输出长文本
​
4. 参考音频的最佳实践
提供参考音频的高质量样本可以提升语音克隆效果。
​
4.1 音频质量指南
仅限单一说话人
吐字清晰、稳定的音量、音调和情绪
简短的停顿（建议 0.5 秒）
理想情况：无背景噪音、专业录音质量、无房间回声
建议时间8～10s左右
​
4.2 文件格式
支持格式：mp3, wav, pcm, opus
推荐使用 192kbps 以上的 mp3 以避免质量损失
未压缩格式（例如 WAV）提供的额外优势有限
​
5. 使用示例
5.1 使用系统预置音色

from pathlib import Path
from openai import OpenAI

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.cn/account/ak 获取
    base_url="https://api.siliconflow.cn/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", # 支持 fishaudio / GPT-SoVITS / CosyVoice2-0.5B 系列模型
  voice="FunAudioLLM/CosyVoice2-0.5B:alex", # 系统预置音色
  # 用户输入信息
  input="你能用高兴的情感说吗？<|endofprompt|>今天真是太开心了，马上要放假了！I'm so happy, Spring Festival is coming!",
  response_format="mp3" # 支持 mp3, wav, pcm, opus 格式
) as response:
    response.stream_to_file(speech_file_path)

​
5.2 使用用户预置音色

from pathlib import Path
from openai import OpenAI

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.cn/account/ak 获取
    base_url="https://api.siliconflow.cn/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", # 支持 fishaudio / GPT-SoVITS / CosyVoice2-0.5B 系列模型
  voice="speech:your-voice-name:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd", # 用户上传音色名称，参考
  # 用户输入信息
  input=" 请问你能模仿粤语的口音吗？< |endofprompt| >多保重，早休息。",
  response_format="mp3"
) as response:
    response.stream_to_file(speech_file_path)

​
5.3 使用用户动态音色

from pathlib import Path
from openai import OpenAI
client = OpenAI()

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.cn/account/ak 获取
    base_url="https://api.siliconflow.cn/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", 
  voice="", # 此处传入空值，表示使用动态音色
  # 用户输入信息
  input="  [laughter]有时候，看着小孩子们的天真行为[laughter]，我们总会会心一笑。",
  response_format="mp3",
  extra_body={"references":[
        {
            "audio": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-Alex.mp3", # 参考音频 url。也支持 base64 格式
            "text": "在一无所知中, 梦里的一天结束了，一个新的轮回便会开始", # 参考音频的文字内容
        }
    ]}
) as response:
    response.stream_to_file(speech_file_path)
​
5.4 fnlp/MOSS-TTSD-v0.5 使用示例

# -*- coding: utf-8 -*-
import requests
import json

url = "https://api.siliconflow.cn/v1/audio/speech"
token = "Your-api-key"

request_data = {
                "model": "fnlp/MOSS-TTSD-v0.5",
                "stream": True,
                "input": "[S1]Hello, how are you today?[S2]I'm doing great, thanks for asking![S1]That's wonderful to hear.",
                "references": [
                    {
                        "audio": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-Charles.mp3",
                        "text": "他又躺在那里，眼睛闭着，仍然沉浸在梦境的气氛里。那是个庞杂而亮堂的梦",
                    },
                    {
                        "audio": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-Claire.mp3",
                        "text": "他又躺在那里，眼睛闭着，仍然沉浸在梦境的气氛里。那是个庞杂而亮堂的梦"
                    }
                    ],
                "max_tokens": 1600,
                "response_format": "mp3",
                "speed": 1,
                "gain": 0
                }
headers = {'Content-Type': 'application/json', 'Authorization': "Bearer " + token}
try:
    res = requests.post(url=url, data=json.dumps(request_data), headers=headers)
    if res.status_code != 200:
        print(res.text)
    with open('./test.mp3', 'wb') as file:
        file.write(res.content)
except Exception as e:
    print(request_data)
    print(e)

----------

# API 文档 - 创建文本转语音请求
Generate audio from input text. The data generated by the interface is the binary data of the audio, which requires the user to handle it themselves. Reference:https://docs.siliconflow.cn/capabilities/text-to-speech#5

POST
/audio/speech

curl --request POST \
  --url https://api.siliconflow.cn/v1/audio/speech \
  --header 'Authorization: Bearer <token>' \
  --header 'Content-Type: application/json' \
  --data '{
  "model": "fnlp/MOSS-TTSD-v0.5",
  "input": "[S1]Hello, how are you today?[S2]I'\''m doing great, thanks for asking![S1]That'\''s wonderful to hear "
}'


## Authorizations
​
Authorization
string header required
Use the following format for authentication: Bearer <your api key>

Body
application/json
MOSS-TTSD-v0.5
CosyVoice2-0.5B
​
model
enum<string> required
MOSS-TTSD (text to spoken dialogue) is an open-source bilingual spoken dialogue synthesis model that supports both Chinese and English. It can transform dialogue scripts between two speakers into natural, expressive conversational speech. MOSS-TTSD supports voice cloning and long single-session speech generation, making it ideal for AI podcast production.

To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.

Available options: fnlp/MOSS-TTSD-v0.5 
​
input
string required
The dialogue text uses speaker tags to indicate turns:
[S1]: Indicates Speaker 1 is speaking
[S2]: Indicates Speaker 2 is speaking

Required string length: 1 - 128000
Example:
"[S1]Hello, how are you today?[S2]I'm doing great, thanks for asking![S1]That's wonderful to hear "

​
max_tokens
integer default:2048
The maximum number of tokens to generate. The input + output does not exceed 32k tokens.

Example:
4096

​
references
object[]
The voice field and references field are mutually exclusive. If you want to use scripted dialogue, you need to pass two voice tones through the references field. Scripted dialogue is only available for the moss model.

 child attributes
    audio
    string<uri>
    A URL pointing to an audio file (e.g., https://example.com/audio.mp3).

    ​
    text
    string
    The audio content, which can be either a URL pointing to an audio file or a base64-encoded audio string.

​voice
enum<string>
The "voice" field currently does not support two timbres. If you need to upload two timbres, please use "reference".

Available options: fnlp/MOSS-TTSD-v0.5:alex, fnlp/MOSS-TTSD-v0.5:anna, fnlp/MOSS-TTSD-v0.5:bella, fnlp/MOSS-TTSD-v0.5:benjamin, fnlp/MOSS-TTSD-v0.5:charles, fnlp/MOSS-TTSD-v0.5:claire, fnlp/MOSS-TTSD-v0.5:david, fnlp/MOSS-TTSD-v0.5:diana 
​
response_format
enum<string>default:mp3
The format to audio out. Supported formats are mp3, opus, wav, pcm

Available options: mp3, opus, wav, pcm 
​
sample_rate
numberdefault:32000
Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz.

​
stream
boolean default:true
streaming or not

​
speed
number default:1
The speed of the generated audio. Select a value from 0.25 to 4.0. 1.0 is the default.

Required range: 0.25 <= x <= 4
​
gain
number default:0
Required range: -10 <= x <= 10


## Response
200
application/audio
Generate audio based on the input text. The data generated by the interface is in binary format and requires the user to process it themselves. Reference:https://docs.siliconflow.cn/capabilities/text-to-speech#5

The response is of type file.